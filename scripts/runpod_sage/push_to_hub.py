#!/usr/bin/env python3
"""
Upload a LeRobot dataset to HuggingFace Hub with an honest DatasetCard.

Reads quality_report.json and sage_metadata.json from the dataset directory
to populate provenance information in the README.md.

Usage:
    python push_to_hub.py \
        --dataset-dir /workspace/outputs/kitchen_lerobot \
        --repo-id blueprint-robotics/sage-franka-kitchen-v1 \
        --private

    # Or upload all scenes:
    python push_to_hub.py \
        --dataset-dir /workspace/outputs/all_lerobot \
        --repo-id blueprint-robotics/sage-franka-manipulation-v1
"""

import argparse
import json
import os
import sys
from datetime import datetime, timezone
from pathlib import Path


def generate_dataset_card(
    dataset_dir: Path,
    repo_id: str,
    room_type: str = "unknown",
    num_episodes: int = 0,
    robot_type: str = "franka",
    task_desc: str = "",
) -> str:
    """Generate a HuggingFace-compatible markdown DatasetCard (README.md)."""

    # Try to load metadata from quality report and sage_metadata
    sage_meta = {}
    meta_path = dataset_dir / "sage_metadata.json"
    if meta_path.exists():
        sage_meta = json.loads(meta_path.read_text())
        room_type = sage_meta.get("room_type", room_type)
        num_episodes = sage_meta.get("num_episodes", num_episodes)
        robot_type = sage_meta.get("robot_type", robot_type)

    # Try to load info.json for feature details
    info = {}
    info_path = dataset_dir / "meta" / "info.json"
    if info_path.exists():
        info = json.loads(info_path.read_text())

    total_episodes = info.get("total_episodes", num_episodes)
    fps = info.get("fps", sage_meta.get("fps", 30))

    # Split counts (estimate from ratios if not in info)
    train_count = int(total_episodes * 0.8)
    val_count = int(total_episodes * 0.1)
    test_count = total_episodes - train_count - val_count

    generated_at = datetime.now(timezone.utc).strftime("%Y-%m-%d")

    card = f"""---
license: apache-2.0
task_categories:
- robotics
tags:
- lerobot
- manipulation
- {robot_type}
- simulation
- isaac-sim
- sage
- synthetic
pretty_name: "SAGE {robot_type.title()} Manipulation — {room_type.replace('_', ' ').title()}"
dataset_info:
  features:
    - name: observation.state
      dtype: float32
      shape: [7]
    - name: action
      dtype: float32
      shape: [8]
  splits:
    - name: train
      num_examples: {train_count}
    - name: validation
      num_examples: {val_count}
    - name: test
      num_examples: {test_count}
---

# SAGE {robot_type.title()} Manipulation — {room_type.replace('_', ' ').title()}

Robotic manipulation episodes generated with [SAGE](https://github.com/NVlabs/sage)
scene generation + Isaac Sim physics + {robot_type.title()} robot.

## Dataset Description

| Property | Value |
|----------|-------|
| Robot | {robot_type.title()} (7-DOF + gripper) |
| Scene | {room_type.replace('_', ' ').title()} |
| Episodes | {total_episodes} |
| FPS | {fps} Hz |
| Format | LeRobot v2.0 |
| Generated | {generated_at} |

## Data Provenance (Honest Labeling)

This dataset is **fully synthetic**, generated in NVIDIA Isaac Sim. We provide
transparent per-channel provenance so you know exactly what is physics-based
vs. estimated:

| Channel | Source | Quality |
|---------|--------|---------|
| `observation.state` (joint positions) | PhysX IK solver | **Real** — physics-based |
| `action` (joint commands) | cuRobo / RRT planner | **Real** — computed |
| `observation.images.*` (RGB) | Isaac Sim ray tracing | **Rendered** — photorealistic |
| efforts (if included) | Inverse dynamics estimate | **Estimated** — not real torque |
| contacts (if included) | Proximity heuristic | **Estimated** — not real F/T |
| object poses | Kinematic (objects static) | **Limited** — objects don't move |

**What this means for training:**
- Joint positions + actions + RGB images are high quality and suitable for
  behavior cloning (BC) and vision-language-action (VLA) models.
- Effort and contact channels should NOT be used for force-control policies.
- Objects do not respond to manipulation forces (kinematic mode). This data
  teaches reach-and-grasp trajectories, not object dynamics.

## Scene Details

- **Room type**: {room_type.replace('_', ' ').title()}
- **Objects**: 10-25 procedurally placed objects (SAM3D + SceneSmith)
- **Task**: {task_desc or 'Pick-and-place manipulation'}
- **Quality gates**: Collision repair, floor clamping, surface snapping, SceneSmith fallback

## Usage

```python
from datasets import load_dataset

dataset = load_dataset("{repo_id}")

# Access an episode
episode = dataset["train"][0]
state = episode["observation.state"]   # shape: (7,)
action = episode["action"]             # shape: (8,)
```

## Pipeline

Generated by [BlueprintPipeline](https://github.com/nijelhunt/BlueprintPipeline):
1. **SAGE** (NVlabs): GPT 5.1 agent generates 3D scenes via MCP tool calls
2. **SAM3D** (Meta): Text → image → 3D mesh for each object
3. **Isaac Sim**: Physics-based object placement + collision validation
4. **cuRobo**: GPU-accelerated trajectory planning for Franka
5. **Data collection**: HDF5 recording of joint states + camera frames
6. **Certification**: 10-gate physics certification with per-channel provenance

## Citation

```bibtex
@misc{{blueprint_sage_{room_type}_2026,
  title={{SAGE {robot_type.title()} Manipulation Dataset — {room_type.replace('_', ' ').title()}}},
  author={{BlueprintPipeline}},
  year={{2026}},
  publisher={{HuggingFace}}
}}
```
"""
    return card


def push_to_hub(
    dataset_dir: Path,
    repo_id: str,
    hf_token: str,
    private: bool = False,
    task_desc: str = "",
):
    """Upload a LeRobot dataset directory to HuggingFace Hub."""
    try:
        from huggingface_hub import HfApi
    except ImportError:
        print("ERROR: huggingface_hub not installed. Run: pip install huggingface_hub>=0.20.0")
        sys.exit(1)

    api = HfApi(token=hf_token)

    # Create repo
    print(f"Creating repo: {repo_id} (private={private})")
    api.create_repo(
        repo_id=repo_id,
        repo_type="dataset",
        exist_ok=True,
        private=private,
    )

    # Generate DatasetCard (README.md)
    print("Generating DatasetCard...")
    card = generate_dataset_card(dataset_dir, repo_id, task_desc=task_desc)
    readme_path = dataset_dir / "README.md"
    readme_path.write_text(card)

    # Upload
    print(f"Uploading {dataset_dir} to {repo_id}...")
    api.upload_folder(
        folder_path=str(dataset_dir),
        repo_id=repo_id,
        repo_type="dataset",
        commit_message=f"Upload SAGE LeRobot dataset ({datetime.now(timezone.utc).strftime('%Y-%m-%d')})",
    )

    url = f"https://huggingface.co/datasets/{repo_id}"
    print(f"Upload complete: {url}")
    return url


def main():
    parser = argparse.ArgumentParser(description="Upload LeRobot dataset to HuggingFace Hub")
    parser.add_argument("--dataset-dir", required=True, help="Path to LeRobot dataset directory")
    parser.add_argument("--repo-id", required=True, help="HuggingFace repo ID (e.g. user/dataset-name)")
    parser.add_argument("--private", action="store_true", help="Make the repo private")
    parser.add_argument("--token", default=None, help="HuggingFace token (or set HF_TOKEN env var)")
    parser.add_argument("--task", default="", help="Task description for the DatasetCard")
    args = parser.parse_args()

    hf_token = args.token or os.environ.get("HF_TOKEN")
    if not hf_token:
        print("ERROR: No HuggingFace token. Set HF_TOKEN or pass --token")
        sys.exit(1)

    dataset_dir = Path(args.dataset_dir)
    if not dataset_dir.exists():
        print(f"ERROR: Dataset directory not found: {dataset_dir}")
        sys.exit(1)

    push_to_hub(
        dataset_dir=dataset_dir,
        repo_id=args.repo_id,
        hf_token=hf_token,
        private=args.private,
        task_desc=args.task,
    )


if __name__ == "__main__":
    main()
