"""
Task Implementation - bedroom_manipulation
Generated by BlueprintRecipe

This file implements the task logic for manipulation.
"""

from __future__ import annotations

import torch
from typing import TYPE_CHECKING

from isaaclab.envs import ManagerBasedEnv
from . import reward_functions

if TYPE_CHECKING:
    from .env_cfg import BedroomManipulationEnvCfg


class BedroomManipulationTask:
    """
    Task implementation for bedroom_manipulation.

    Policy: manipulation
    Description: 
    """

    def __init__(self, env: ManagerBasedEnv, cfg: BedroomManipulationEnvCfg):
        self.env = env
        self.cfg = cfg
        self.device = env.device
        self.num_envs = env.num_envs
        # Get scene entity map from config (set in config's __post_init__)
        self.scene_entity_map = getattr(cfg, "scene_entity_map", {'robot': '/World/Robot', 'scene_root': '/World/Bedroom', 'obj_0': '/World/Bedroom/Objects/obj_0', 'obj_1': '/World/Bedroom/Objects/obj_1', 'obj_2': '/World/Bedroom/Objects/obj_2', 'obj_3': '/World/Bedroom/Objects/obj_3', 'obj_4': '/World/Bedroom/Objects/obj_4', 'scene_background': '/World/Bedroom/Objects/scene_background'})
        self.target_name = "obj_0"
        self.ee_frame = "panda_hand"

        # Initialize reward function state variables (CRITICAL for sim2real transfer rewards)
        reward_functions.initialize_reward_state(env)

        # Task state
        self._setup_task_state()

    def _setup_task_state(self):
        """Initialize task-specific state tensors."""
        self.task_success = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
        self.object_dropped = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)

    def reset(self, env_ids: torch.Tensor):
        """Reset task state for specified environments."""
        self.task_success[env_ids] = False
        self.object_dropped[env_ids] = False

    def compute_observations(self) -> dict[str, torch.Tensor]:
        """Compute task-specific observations and merge with manager outputs."""

        observations = self.env.observation_manager.compute()
        target = self._get_scene_entity(self.target_name)
        if target is not None:
            target_pose = torch.cat([target.data.root_pos_w, target.data.root_quat_w], dim=-1)
            observations["target_pose"] = target_pose

        return observations

    def compute_rewards(self) -> dict[str, torch.Tensor]:
        """Compute reward components and integrate with RewardManager."""

        reward_terms = self.env.reward_manager.compute()
        target = self._get_scene_entity(self.target_name)
        robot = self.env.scene.get("robot")

        if target is not None and robot is not None:
            ee_pos = self._get_ee_pos(robot)
            dist_to_target = torch.norm(target.data.root_pos_w - ee_pos, dim=-1)
            dense_reach = 1.0 - torch.tanh(4.0 * dist_to_target)
            close_enough = dist_to_target < 0.05

            reward_terms.setdefault("dense_reach", dense_reach)
            reward_terms.setdefault("proximity_success", close_enough.float() * 5.0)
            self.task_success = self.task_success | close_enough

        total = torch.zeros(self.num_envs, device=self.device)
        for value in reward_terms.values():
            total = total + value
        reward_terms["total"] = total
        return reward_terms

    def compute_terminations(self) -> dict[str, torch.Tensor]:
        """Compute termination conditions including manager-driven terms."""

        terminations = self.env.termination_manager.compute()
        terminations.setdefault("task_success", self.task_success)

        target = self._get_scene_entity(self.target_name)
        if target is not None:
            dropped = target.data.root_pos_w[:, 2] < -0.05
            self.object_dropped = self.object_dropped | dropped
            terminations.setdefault("object_dropped", dropped)

        return terminations

    def _get_ee_pos(self, robot=None) -> torch.Tensor:
        """Get end-effector position."""
        robot = robot or self.env.scene.get("robot")
        return robot.data.body_pos_w[:, robot.find_bodies(self.ee_frame)[0]]

    def _get_scene_entity(self, name: str):
        """Resolve a scene entity using the generated map for prim paths."""

        entity = self.env.scene.get(name)
        if entity is not None:
            return entity

        prim_path = self.scene_entity_map.get(name)
        if prim_path:
            return self.env.scene.get(prim_path)
        return None
