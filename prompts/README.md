# prompts

## Purpose / scope
Stores prompt templates used by LLM-driven components.

## Primary entrypoints
- `object_reconstruction_prompt.md`

## Required inputs / outputs
- **Inputs:** prompt text consumed by LLM clients.
- **Outputs:** prompt strings used in LLM requests.

## Key environment variables
- Variables configuring LLM providers (e.g., API keys) are set in the consuming services.

## How to run locally
- Edit prompt files and run the consuming pipeline or tests to validate changes.

