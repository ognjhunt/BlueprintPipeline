"""
Domain Randomization Hooks - kitchen_dish_loading
Generated by BlueprintRecipe

These hooks are designed to work with Isaac Lab's EventManager.
They write directly to PhysX for RL speed mode compatibility.
"""

from __future__ import annotations

import torch
from typing import TYPE_CHECKING

import omni.isaac.lab.utils.math as math_utils
from omni.isaac.lab.envs import ManagerBasedEnv
from omni.isaac.lab.managers import EventTermCfg, SceneEntityCfg

if TYPE_CHECKING:
    from omni.isaac.lab.envs import ManagerBasedEnvCfg


def randomize_object_poses(
    env: ManagerBasedEnv,
    env_ids: torch.Tensor,
    position_range: tuple[float, float, float, float, float, float] = (-0.2, 0.2, -0.2, 0.2, 0.0, 0.1),
    rotation_range: tuple[float, float] = (0.0, 6.28),
):
    """
    Randomize object poses on reset.

    Note: This writes directly to PhysX buffers for RL speed mode compatibility.
    """
    num_envs = len(env_ids)

    # Get objects to randomize
    objects = env.scene.get("objects")
    if objects is None:
        return

    # Generate random positions
    pos = torch.zeros(num_envs, 3, device=env.device)
    pos[:, 0] = torch.rand(num_envs, device=env.device) * (position_range[1] - position_range[0]) + position_range[0]
    pos[:, 1] = torch.rand(num_envs, device=env.device) * (position_range[3] - position_range[2]) + position_range[2]
    pos[:, 2] = torch.rand(num_envs, device=env.device) * (position_range[5] - position_range[4]) + position_range[4]

    # Generate random rotations (around Z axis)
    yaw = torch.rand(num_envs, device=env.device) * (rotation_range[1] - rotation_range[0]) + rotation_range[0]
    quat = math_utils.quat_from_euler_xyz(
        torch.zeros_like(yaw),
        torch.zeros_like(yaw),
        yaw
    )

    # Write to physics
    objects.write_root_pose_to_sim(
        torch.cat([pos, quat], dim=-1),
        env_ids
    )


def randomize_articulation_state(
    env: ManagerBasedEnv,
    env_ids: torch.Tensor,
    articulation_name: str = "articulated_object",
    joint_range: tuple[float, float] = (0.0, 1.0),
):
    """
    Randomize articulation joint states on reset.
    """
    num_envs = len(env_ids)

    articulation = env.scene.get(articulation_name)
    if articulation is None:
        return

    # Generate random joint positions
    num_joints = articulation.num_joints
    joint_pos = torch.rand(num_envs, num_joints, device=env.device)
    joint_pos = joint_pos * (joint_range[1] - joint_range[0]) + joint_range[0]

    # Respect joint limits
    joint_limits = articulation.data.joint_limits
    joint_pos = torch.clamp(
        joint_pos,
        joint_limits[..., 0],
        joint_limits[..., 1]
    )

    # Write to physics
    articulation.write_joint_state_to_sim(
        joint_pos,
        torch.zeros_like(joint_pos),  # zero velocity
        env_ids=env_ids
    )


def randomize_lighting(
    env: ManagerBasedEnv,
    env_ids: torch.Tensor,
    intensity_range: tuple[float, float] = (500.0, 2000.0),
):
    """
    Randomize lighting intensity and orientation using direct PhysX writes.

    """
    light = env.scene.get("light")
    if light is None:
        return

    num_envs = len(env_ids)
    intensity = torch.rand(num_envs, device=env.device)
    intensity = intensity * (intensity_range[1] - intensity_range[0]) + intensity_range[0]

    if hasattr(light, "write_attribute_to_sim"):
        light.write_attribute_to_sim("intensity", intensity, env_ids)

    # Randomize yaw for dome lights to alter shadows/reflections
    yaw = torch.rand(num_envs, device=env.device) * 6.28318
    quat = math_utils.quat_from_euler_xyz(
        torch.zeros_like(yaw), torch.zeros_like(yaw), yaw
    )
    pose = torch.zeros(num_envs, 7, device=env.device)
    pose[:, 3:] = quat
    if hasattr(light, "write_root_pose_to_sim"):
        light.write_root_pose_to_sim(pose, env_ids)


def randomize_materials(
    env: ManagerBasedEnv,
    env_ids: torch.Tensor,
    friction_range: tuple[float, float] = (0.3, 1.0),
    restitution_range: tuple[float, float] = (0.0, 0.3),
):
    """
    Randomize physics material properties.
    """
    rigid_objects = env.scene.get("objects") or env.scene.get("rigid_objects")
    if rigid_objects is None:
        return

    num_envs = len(env_ids)
    friction = torch.rand(num_envs, device=env.device)
    friction = friction * (friction_range[1] - friction_range[0]) + friction_range[0]
    restitution = torch.rand(num_envs, device=env.device)
    restitution = restitution * (restitution_range[1] - restitution_range[0]) + restitution_range[0]

    if hasattr(rigid_objects, "write_material_properties_to_sim"):
        rigid_objects.write_material_properties_to_sim(
            friction_coefficients=friction,
            restitution_coefficients=restitution,
            env_ids=env_ids,
        )
    elif hasattr(rigid_objects, "write_rigid_body_properties_to_sim"):
        props = rigid_objects.data.rigid_body_properties
        props["friction"] = friction
        props["restitution"] = restitution
        rigid_objects.write_rigid_body_properties_to_sim(props, env_ids=env_ids)


# ============================================================================
# SIM2REAL TRANSFER: Action/Observation Delay Randomization
# ============================================================================
# These are CRITICAL for sim2real transfer. Real robots have latency from:
# - Communication delays (network, USB, CAN bus)
# - Sensor processing time (camera exposure, filtering)
# - Control loop delays (safety checks, interpolation)
# Training with delay randomization prevents policies from exploiting
# unrealistic instantaneous response in simulation.


class ActionDelayBuffer:
    """
    Circular buffer for action delay randomization.

    Delays actions by a random number of steps to simulate real-world
    communication and processing latency. This is CRITICAL for sim2real
    transfer as it prevents policies from exploiting instantaneous response.
    """

    def __init__(self, num_envs: int, action_dim: int, max_delay: int, device: torch.device):
        self.num_envs = num_envs
        self.action_dim = action_dim
        self.max_delay = max_delay
        self.device = device

        # Circular buffer: [num_envs, max_delay + 1, action_dim]
        self.buffer = torch.zeros(num_envs, max_delay + 1, action_dim, device=device)
        self.write_idx = torch.zeros(num_envs, dtype=torch.long, device=device)
        self.delays = torch.zeros(num_envs, dtype=torch.long, device=device)

    def set_delays(self, delays: torch.Tensor):
        """Set per-environment delays (0 to max_delay)."""
        self.delays = delays.clamp(0, self.max_delay).long()

    def push(self, actions: torch.Tensor) -> torch.Tensor:
        """Push new actions and return delayed actions."""
        # Write new actions to buffer
        batch_indices = torch.arange(self.num_envs, device=self.device)
        self.buffer[batch_indices, self.write_idx] = actions

        # Read delayed actions
        read_idx = (self.write_idx - self.delays) % (self.max_delay + 1)
        delayed_actions = self.buffer[batch_indices, read_idx]

        # Advance write pointer
        self.write_idx = (self.write_idx + 1) % (self.max_delay + 1)

        return delayed_actions

    def reset(self, env_ids: torch.Tensor, default_action: torch.Tensor):
        """Reset buffer for specified environments."""
        self.buffer[env_ids] = default_action.unsqueeze(1).expand(-1, self.max_delay + 1, -1)
        self.write_idx[env_ids] = 0


class ObservationDelayBuffer:
    """
    Circular buffer for observation delay randomization.

    Delays observations to simulate sensor latency, processing time,
    and communication delays. Helps policies become robust to real-world
    sensing delays.
    """

    def __init__(self, num_envs: int, obs_dim: int, max_delay: int, device: torch.device):
        self.num_envs = num_envs
        self.obs_dim = obs_dim
        self.max_delay = max_delay
        self.device = device

        self.buffer = torch.zeros(num_envs, max_delay + 1, obs_dim, device=device)
        self.write_idx = torch.zeros(num_envs, dtype=torch.long, device=device)
        self.delays = torch.zeros(num_envs, dtype=torch.long, device=device)

    def set_delays(self, delays: torch.Tensor):
        """Set per-environment delays."""
        self.delays = delays.clamp(0, self.max_delay).long()

    def push(self, observations: torch.Tensor) -> torch.Tensor:
        """Push new observations and return delayed observations."""
        batch_indices = torch.arange(self.num_envs, device=self.device)
        self.buffer[batch_indices, self.write_idx] = observations

        read_idx = (self.write_idx - self.delays) % (self.max_delay + 1)
        delayed_obs = self.buffer[batch_indices, read_idx]

        self.write_idx = (self.write_idx + 1) % (self.max_delay + 1)
        return delayed_obs

    def reset(self, env_ids: torch.Tensor, default_obs: torch.Tensor):
        """Reset buffer for specified environments."""
        self.buffer[env_ids] = default_obs.unsqueeze(1).expand(-1, self.max_delay + 1, -1)
        self.write_idx[env_ids] = 0


def randomize_action_delay(
    env: ManagerBasedEnv,
    env_ids: torch.Tensor,
    delay_range: tuple[int, int] = (0, 3),
):
    """
    Randomize action delay for specified environments.

    Args:
        env: The environment instance
        env_ids: Environments to randomize
        delay_range: (min_steps, max_steps) delay range

    This simulates real-world communication and processing delays:
    - 0 steps: Ideal (unrealistic for real robots)
    - 1-2 steps: Typical for well-tuned systems
    - 3+ steps: Systems with significant latency (wireless, vision processing)
    """
    num_envs = len(env_ids)

    # Generate random delays
    delays = torch.randint(
        delay_range[0], delay_range[1] + 1,
        (num_envs,), device=env.device
    )

    # Store in env for use during step
    if not hasattr(env, "_action_delay_buffer"):
        # Initialize buffer on first use
        action_dim = env.action_manager.action.shape[-1] if hasattr(env, "action_manager") else 7
        env._action_delay_buffer = ActionDelayBuffer(
            env.num_envs, action_dim, delay_range[1], env.device
        )

    env._action_delay_buffer.set_delays(delays)


def randomize_observation_delay(
    env: ManagerBasedEnv,
    env_ids: torch.Tensor,
    delay_range: tuple[int, int] = (0, 2),
):
    """
    Randomize observation delay for specified environments.

    Args:
        env: The environment instance
        env_ids: Environments to randomize
        delay_range: (min_steps, max_steps) delay range

    This simulates sensor latency:
    - Camera exposure and readout time
    - Image processing and feature extraction
    - Network transmission delays
    - Filter settling time
    """
    num_envs = len(env_ids)

    delays = torch.randint(
        delay_range[0], delay_range[1] + 1,
        (num_envs,), device=env.device
    )

    if not hasattr(env, "_observation_delay_buffer"):
        obs_dim = env.observation_manager.observation.shape[-1] if hasattr(env, "observation_manager") else 32
        env._observation_delay_buffer = ObservationDelayBuffer(
            env.num_envs, obs_dim, delay_range[1], env.device
        )

    env._observation_delay_buffer.set_delays(delays)


def randomize_actuator_dynamics(
    env: ManagerBasedEnv,
    env_ids: torch.Tensor,
    strength_range: tuple[float, float] = (0.8, 1.2),
    damping_range: tuple[float, float] = (0.9, 1.1),
):
    """
    Randomize actuator strength and damping.

    Simulates variation in motor performance:
    - Motor aging and wear
    - Temperature effects on motor efficiency
    - Manufacturing tolerances
    - Load-dependent efficiency changes
    """
    robot = env.scene.get("robot")
    if robot is None:
        return

    num_envs = len(env_ids)

    # Randomize actuator strength (gain multiplier)
    strength = torch.rand(num_envs, device=env.device)
    strength = strength * (strength_range[1] - strength_range[0]) + strength_range[0]

    # Randomize damping
    damping = torch.rand(num_envs, device=env.device)
    damping = damping * (damping_range[1] - damping_range[0]) + damping_range[0]

    # Store for use in action processing
    if not hasattr(env, "_actuator_strength"):
        env._actuator_strength = torch.ones(env.num_envs, device=env.device)
        env._actuator_damping = torch.ones(env.num_envs, device=env.device)

    env._actuator_strength[env_ids] = strength
    env._actuator_damping[env_ids] = damping


# Event term configurations for EventManager
def get_reset_events() -> dict[str, EventTermCfg]:
    """Get reset event configurations including sim2real transfer events."""
    return {
        "randomize_objects": EventTermCfg(
            func=randomize_object_poses,
            mode="reset",
        ),
        "randomize_articulations": EventTermCfg(
            func=randomize_articulation_state,
            mode="reset",
        ),
        "randomize_action_delay": EventTermCfg(
            func=randomize_action_delay,
            mode="reset",
            params={"delay_range": (0, 3)},
        ),
        "randomize_observation_delay": EventTermCfg(
            func=randomize_observation_delay,
            mode="reset",
            params={"delay_range": (0, 2)},
        ),
        "randomize_actuator_dynamics": EventTermCfg(
            func=randomize_actuator_dynamics,
            mode="reset",
            params={"strength_range": (0.85, 1.15), "damping_range": (0.9, 1.1)},
        ),
    }


def get_interval_events() -> dict[str, EventTermCfg]:
    """Get interval event configurations."""
    return {
        # Periodic material/lighting randomization could go here
        # for longer training runs
    }
