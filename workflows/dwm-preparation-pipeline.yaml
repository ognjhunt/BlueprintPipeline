# dwm-preparation-pipeline.yaml
#
# Google Cloud Workflows pipeline that:
#   1. Triggers on completion marker file from regen3d-job (.regen3d_complete)
#   2. Runs dwm-preparation-job to generate DWM conditioning bundles
#   3. Writes .dwm_complete marker when finished
#
# Trigger: Cloud Storage object finalized event for .regen3d_complete
#
# NOTE: This pipeline runs in parallel with usd-assembly-pipeline and dream2flow-preparation-pipeline
# (all trigger on the same .regen3d_complete marker). This is safe because:
# - Each pipeline writes to different output prefixes (dwm/*, usd/*, dream2flow/*)
# - No shared state is modified
# - Idempotency checks prevent duplicate processing
#
# DWM (Dexterous World Model) generates egocentric interaction videos from:
#   - Static scene video (rendered from 3D scene)
#   - Hand mesh video (rendered MANO hand meshes)
#   - Text prompt (semantic action description)
#
# Reference: https://snuvclab.github.io/dwm/
#            arXiv:2512.17907
#
# EventArc Setup:
#   gcloud eventarc triggers create dwm-preparation-trigger \
#     --location=us-central1 \
#     --service-account="${WORKFLOW_SA}@${PROJECT_ID}.iam.gserviceaccount.com" \
#     --destination-workflow=dwm-preparation-pipeline \
#     --destination-workflow-location=us-central1 \
#     --event-filters="type=google.cloud.storage.object.v1.finalized" \
#     --event-filters="bucket=${BUCKET}" \
#     --event-data-content-type="application/json"

main:
  params: [event]
  steps:
    - log_event:
        call: sys.log
        args:
          text: ${event}
          severity: "INFO"
        next: extract

    - extract:
        assign:
          - bucket: ${event.data.bucket}
          - object: ${event.data.name}
          - projectId: '${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}'
          - region: "us-central1"
          - enableDwm: '${sys.get_env("ENABLE_DWM") != null and text.lower(sys.get_env("ENABLE_DWM")) == "true"}'
        next: filter_completion_markers

    # Filter for .regen3d_complete marker files
    # This runs in parallel with usd-assembly-pipeline on the same trigger
    - filter_completion_markers:
        switch:
          - condition: '${text.match_regex(object, "^scenes/.+/assets/\\.regen3d_complete$")}'
            next: derive
        next: skip

    - derive:
        assign:
          - parts: '${text.split(object, "/")}'
          - sceneId: ${parts[1]}
          - assetsPrefix: '${"scenes/" + sceneId + "/assets"}'
          - usdPrefix: '${"scenes/" + sceneId + "/usd"}'
          - dwmPrefix: '${"scenes/" + sceneId + "/dwm"}'
          - dwmJobName: "dwm-preparation-job"
          # Explicitly set to the Cloud Run default for consistency/metrics.
          - dwmTimeoutSeconds: 3600
          - dwmCompleteMarker: '${"scenes/" + sceneId + "/dwm/.dwm_complete"}'
          - dwmInferenceJobName: "dwm-inference-job"
          # Explicitly set to the Cloud Run default for consistency/metrics.
          - dwmInferenceTimeoutSeconds: 3600
          - dwmInferenceCompleteMarker: '${"scenes/" + sceneId + "/dwm/.dwm_inference_complete"}'
          - dwmFailedMarker: '${"scenes/" + sceneId + "/dwm/.failed"}'
          - dwmLegacyFailedMarker: '${"scenes/" + sceneId + "/dwm/.dwm_failed"}'
          - dwmInferenceFailedMarker: '${"scenes/" + sceneId + "/dwm/.failed"}'
          - dwmInferenceLegacyFailedMarker: '${"scenes/" + sceneId + "/dwm/.dwm_inference_failed"}'
        next: check_dwm_enabled

    - check_dwm_enabled:
        switch:
          - condition: ${enableDwm}
            next: check_already_processed
        next: log_dwm_disabled

    - log_dwm_disabled:
        call: sys.log
        args:
          text: '${"DWM preparation is disabled for scene " + sceneId + " (ENABLE_DWM not set)"}'
          severity: "INFO"
        next: skip

    # Check if DWM bundles already generated (idempotence)
    - check_already_processed:
        try:
          call: googleapis.storage.v1.objects.get
          args:
            bucket: ${bucket}
            object: ${dwmCompleteMarker}
          result: existingMarker
        except:
          as: e
          steps:
            - check_not_found:
                switch:
                  - condition: '${e.code == 404}'
                    next: log_start
                next: raise_check_error
        next: skip_already_processed

    - skip_already_processed:
        call: sys.log
        args:
          text: '${"DWM bundles already generated for scene " + sceneId + " - skipping"}'
          severity: "INFO"
        next: skip

    - raise_check_error:
        raise: '${e}'

    - log_start:
        call: sys.log
        args:
          text: '${"DWM preparation triggered for scene " + sceneId}'
          severity: "INFO"
        next: init_dwm_metrics

    - init_dwm_metrics:
        assign:
          - dwmStartTime: '${time.format(sys.now())}'
        next: emit_dwm_metrics_start

    - emit_dwm_metrics_start:
        call: sys.log
        args:
          data:
            bp_metric: "job_invocation"
            event: "start"
            workflow: "dwm-preparation-pipeline"
            job: ${dwmJobName}
            scene_id: ${sceneId}
            timeout_seconds: ${dwmTimeoutSeconds}
            duration_seconds: 0
            timeout_usage_ratio: 0
            timed_out: false
            status: "STARTED"
            start_time: ${dwmStartTime}
          severity: "INFO"
        next: run_dwm_job

    # Run the DWM preparation job
    - run_dwm_job:
        try:
          call: googleapis.run.v2.projects.locations.jobs.run
          args:
            name: '${"projects/" + projectId + "/locations/" + region + "/jobs/" + dwmJobName}'
            body:
              overrides:
                containerOverrides:
                  - env:
                      - name: BUCKET
                        value: ${bucket}
                      - name: SCENE_ID
                        value: ${sceneId}
                      - name: ASSETS_PREFIX
                        value: ${assetsPrefix}
                      - name: USD_PREFIX
                        value: ${usdPrefix}
                      - name: DWM_PREFIX
                        value: ${dwmPrefix}
                      - name: NUM_TRAJECTORIES
                        value: "5"
                      - name: RESOLUTION_WIDTH
                        value: "720"
                      - name: RESOLUTION_HEIGHT
                        value: "480"
                      - name: NUM_FRAMES
                        value: "49"
                      - name: FPS
                        value: "24"
              timeout: '${string(dwmTimeoutSeconds) + "s"}'
          result: dwmExec
        retry:
          predicate: ${http.default_retry_predicate}
          max_retries: 3
          backoff:
            initial_delay: 2
            max_delay: 30
            multiplier: 2
        except:
          as: e
          steps:
            - log_dwm_retry_exhausted:
                call: sys.log
                args:
                  data:
                    bp_metric: "job_retry_exhausted"
                    workflow: "dwm-preparation-pipeline"
                    job: ${dwmJobName}
                    scene_id: ${sceneId}
                    retry_max: 3
                    error: ${e.message}
                  severity: "ERROR"
            - capture_dwm_failure_metrics:
                assign:
                  - dwmEndTime: '${time.format(sys.now())}'
                  - dwmDurationSeconds: '${time.parse(dwmEndTime) - time.parse(dwmStartTime)}'
                  - dwmTimeoutUsageRatio: '${dwmDurationSeconds / dwmTimeoutSeconds}'
                  - dwmTimedOut: '${dwmDurationSeconds >= dwmTimeoutSeconds}'
            - emit_dwm_metrics_failed:
                call: sys.log
                args:
                  data:
                    bp_metric: "job_invocation"
                    event: "complete"
                    workflow: "dwm-preparation-pipeline"
                    job: ${dwmJobName}
                    scene_id: ${sceneId}
                    timeout_seconds: ${dwmTimeoutSeconds}
                    duration_seconds: ${dwmDurationSeconds}
                    timeout_usage_ratio: ${dwmTimeoutUsageRatio}
                    timed_out: ${dwmTimedOut}
                    status: "FAILED"
                    start_time: ${dwmStartTime}
                    end_time: ${dwmEndTime}
                  severity: "ERROR"
            - log_dwm_job_error:
                call: sys.log
                args:
                  text: '${"Failed to start DWM job after retries: " + e.message}'
                  severity: "ERROR"
            - write_dwm_start_failure_marker:
                call: googleapis.storage.v1.objects.insert
                args:
                  bucket: ${bucket}
                  name: ${dwmFailedMarker}
                  uploadType: "media"
                  body: ${json.encode({
                    "scene_id": sceneId,
                    "job_name": dwmJobName,
                    "status": "failed",
                    "timestamp": time.format(sys.now()),
                    "error": {
                      "code": "dwm_start_failed",
                      "message": e.message,
                      "type": "workflow_failure",
                      "stack_trace": null
                    },
                    "context": {
                      "workflow_execution_id": sys.get_env("GOOGLE_CLOUD_WORKFLOW_EXECUTION_ID"),
                      "attempt_number": 1,
                      "config_context": {
                        "dwm_prefix": dwmPrefix
                      }
                    }
                  })}
            - raise_dwm_job_error:
                raise: ${e}
        next: set_dwm_execution_name

    - set_dwm_execution_name:
        # jobs.run returns a long-running operation; prefer the execution name from metadata when present
        assign:
          - dwmExecutionName: '${if(dwmExec.metadata != null and dwmExec.metadata.name != null, dwmExec.metadata.name, dwmExec.name)}'
        next: wait_for_dwm

    # Poll for job completion
    - wait_for_dwm:
        call: googleapis.run.v2.projects.locations.jobs.executions.get
        args:
          name: ${dwmExecutionName}
        result: dwmStatus
        next: check_dwm_status

    - check_dwm_status:
        assign:
          - dwmState: '${if(dwmStatus.state != null, dwmStatus.state, if(dwmStatus.status != null, dwmStatus.status.state, null))}'
          - dwmFailedCount: '${if(dwmStatus.failedCount != null, dwmStatus.failedCount, if(dwmStatus.status != null, dwmStatus.status.failedCount, null))}'
          - dwmSucceededCount: '${if(dwmStatus.succeededCount != null, dwmStatus.succeededCount, if(dwmStatus.status != null, dwmStatus.status.succeededCount, null))}'
        next: dwm_status_switch

    - dwm_status_switch:
        switch:
          - condition: '${dwmState == "FAILED" or (dwmFailedCount != null and dwmFailedCount > 0)}'
            next: dwm_failed
          - condition: '${dwmState == "SUCCEEDED" or (dwmSucceededCount != null and dwmSucceededCount > 0)}'
            next: log_dwm_complete
        next: wait_dwm_poll

    - wait_dwm_poll:
        call: sys.sleep
        args:
          seconds: 10
        next: wait_for_dwm

    - log_dwm_complete:
        assign:
          - dwmEndTime: '${time.format(sys.now())}'
          - dwmDurationSeconds: '${time.parse(dwmEndTime) - time.parse(dwmStartTime)}'
          - dwmTimeoutUsageRatio: '${dwmDurationSeconds / dwmTimeoutSeconds}'
          - dwmTimedOut: '${dwmDurationSeconds >= dwmTimeoutSeconds}'
        next: emit_dwm_metrics_complete

    - emit_dwm_metrics_complete:
        call: sys.log
        args:
          data:
            bp_metric: "job_invocation"
            event: "complete"
            workflow: "dwm-preparation-pipeline"
            job: ${dwmJobName}
            scene_id: ${sceneId}
            timeout_seconds: ${dwmTimeoutSeconds}
            duration_seconds: ${dwmDurationSeconds}
            timeout_usage_ratio: ${dwmTimeoutUsageRatio}
            timed_out: ${dwmTimedOut}
            status: "SUCCEEDED"
            start_time: ${dwmStartTime}
            end_time: ${dwmEndTime}
          severity: "INFO"
        next: log_dwm_complete_message

    - log_dwm_complete_message:
        call: sys.log
        args:
          text: '${"DWM preparation completed for scene " + sceneId}'
          severity: "INFO"
        next: write_completion_marker

    # Write completion marker for downstream processes
    - write_completion_marker:
        call: googleapis.storage.v1.objects.insert
        args:
          bucket: ${bucket}
          name: ${dwmCompleteMarker}
          uploadType: "media"
          body: '${"{\"scene_id\": \"" + sceneId + "\", \"status\": \"completed\", \"timestamp\": \"" + time.format(sys.now()) + "\"}"}'
        result: markerResult
        next: log_inference_start

    - log_inference_start:
        call: sys.log
        args:
          text: '${"Starting DWM inference for scene " + sceneId}'
          severity: "INFO"
        next: init_dwm_inference_metrics

    - init_dwm_inference_metrics:
        assign:
          - dwmInferenceStartTime: '${time.format(sys.now())}'
        next: emit_dwm_inference_metrics_start

    - emit_dwm_inference_metrics_start:
        call: sys.log
        args:
          data:
            bp_metric: "job_invocation"
            event: "start"
            workflow: "dwm-preparation-pipeline"
            job: ${dwmInferenceJobName}
            scene_id: ${sceneId}
            timeout_seconds: ${dwmInferenceTimeoutSeconds}
            duration_seconds: 0
            timeout_usage_ratio: 0
            timed_out: false
            status: "STARTED"
            start_time: ${dwmInferenceStartTime}
          severity: "INFO"
        next: run_dwm_inference_job

    # Run the DWM inference job
    - run_dwm_inference_job:
        try:
          call: googleapis.run.v2.projects.locations.jobs.run
          args:
            name: '${"projects/" + projectId + "/locations/" + region + "/jobs/" + dwmInferenceJobName}'
            body:
              overrides:
                containerOverrides:
                  - env:
                      - name: BUCKET
                        value: ${bucket}
                      - name: SCENE_ID
                        value: ${sceneId}
                      - name: DWM_PREFIX
                        value: ${dwmPrefix}
              timeout: '${string(dwmInferenceTimeoutSeconds) + "s"}'
          result: dwmInferenceExec
        retry:
          predicate: ${http.default_retry_predicate}
          max_retries: 3
          backoff:
            initial_delay: 2
            max_delay: 30
            multiplier: 2
        except:
          as: e
          steps:
            - log_dwm_inference_retry_exhausted:
                call: sys.log
                args:
                  data:
                    bp_metric: "job_retry_exhausted"
                    workflow: "dwm-preparation-pipeline"
                    job: ${dwmInferenceJobName}
                    scene_id: ${sceneId}
                    retry_max: 3
                    error: ${e.message}
                  severity: "ERROR"
            - capture_dwm_inference_failure_metrics:
                assign:
                  - dwmInferenceEndTime: '${time.format(sys.now())}'
                  - dwmInferenceDurationSeconds: '${time.parse(dwmInferenceEndTime) - time.parse(dwmInferenceStartTime)}'
                  - dwmInferenceTimeoutUsageRatio: '${dwmInferenceDurationSeconds / dwmInferenceTimeoutSeconds}'
                  - dwmInferenceTimedOut: '${dwmInferenceDurationSeconds >= dwmInferenceTimeoutSeconds}'
            - emit_dwm_inference_metrics_failed:
                call: sys.log
                args:
                  data:
                    bp_metric: "job_invocation"
                    event: "complete"
                    workflow: "dwm-preparation-pipeline"
                    job: ${dwmInferenceJobName}
                    scene_id: ${sceneId}
                    timeout_seconds: ${dwmInferenceTimeoutSeconds}
                    duration_seconds: ${dwmInferenceDurationSeconds}
                    timeout_usage_ratio: ${dwmInferenceTimeoutUsageRatio}
                    timed_out: ${dwmInferenceTimedOut}
                    status: "FAILED"
                    start_time: ${dwmInferenceStartTime}
                    end_time: ${dwmInferenceEndTime}
                  severity: "ERROR"
            - log_dwm_inference_job_error:
                call: sys.log
                args:
                  text: '${"Failed to start DWM inference job after retries: " + e.message}'
                  severity: "ERROR"
            - write_dwm_inference_start_failure_marker:
                call: googleapis.storage.v1.objects.insert
                args:
                  bucket: ${bucket}
                  name: ${dwmInferenceFailedMarker}
                  uploadType: "media"
                  body: ${json.encode({
                    "scene_id": sceneId,
                    "job_name": dwmInferenceJobName,
                    "status": "failed",
                    "timestamp": time.format(sys.now()),
                    "error": {
                      "code": "dwm_inference_start_failed",
                      "message": e.message,
                      "type": "workflow_failure",
                      "stack_trace": null
                    },
                    "context": {
                      "workflow_execution_id": sys.get_env("GOOGLE_CLOUD_WORKFLOW_EXECUTION_ID"),
                      "attempt_number": 1,
                      "config_context": {
                        "dwm_prefix": dwmPrefix
                      }
                    }
                  })}
            - raise_dwm_inference_job_error:
                raise: ${e}
        next: set_dwm_inference_execution_name

    - set_dwm_inference_execution_name:
        assign:
          - dwmInferenceExecutionName: '${if(dwmInferenceExec.metadata != null and dwmInferenceExec.metadata.name != null, dwmInferenceExec.metadata.name, dwmInferenceExec.name)}'
        next: wait_for_dwm_inference

    - wait_for_dwm_inference:
        call: googleapis.run.v2.projects.locations.jobs.executions.get
        args:
          name: ${dwmInferenceExecutionName}
        result: dwmInferenceStatus
        next: check_dwm_inference_status

    - check_dwm_inference_status:
        assign:
          - dwmInferenceState: '${if(dwmInferenceStatus.state != null, dwmInferenceStatus.state, if(dwmInferenceStatus.status != null, dwmInferenceStatus.status.state, null))}'
          - dwmInferenceFailedCount: '${if(dwmInferenceStatus.failedCount != null, dwmInferenceStatus.failedCount, if(dwmInferenceStatus.status != null, dwmInferenceStatus.status.failedCount, null))}'
          - dwmInferenceSucceededCount: '${if(dwmInferenceStatus.succeededCount != null, dwmInferenceStatus.succeededCount, if(dwmInferenceStatus.status != null, dwmInferenceStatus.status.succeededCount, null))}'
        next: dwm_inference_status_switch

    - dwm_inference_status_switch:
        switch:
          - condition: '${dwmInferenceState == "FAILED" or (dwmInferenceFailedCount != null and dwmInferenceFailedCount > 0)}'
            next: dwm_inference_failed
          - condition: '${dwmInferenceState == "SUCCEEDED" or (dwmInferenceSucceededCount != null and dwmInferenceSucceededCount > 0)}'
            next: log_dwm_inference_complete
        next: wait_inference_poll

    - wait_inference_poll:
        call: sys.sleep
        args:
          seconds: 10
        next: wait_for_dwm_inference

    - log_dwm_inference_complete:
        assign:
          - dwmInferenceEndTime: '${time.format(sys.now())}'
          - dwmInferenceDurationSeconds: '${time.parse(dwmInferenceEndTime) - time.parse(dwmInferenceStartTime)}'
          - dwmInferenceTimeoutUsageRatio: '${dwmInferenceDurationSeconds / dwmInferenceTimeoutSeconds}'
          - dwmInferenceTimedOut: '${dwmInferenceDurationSeconds >= dwmInferenceTimeoutSeconds}'
        next: emit_dwm_inference_metrics_complete

    - emit_dwm_inference_metrics_complete:
        call: sys.log
        args:
          data:
            bp_metric: "job_invocation"
            event: "complete"
            workflow: "dwm-preparation-pipeline"
            job: ${dwmInferenceJobName}
            scene_id: ${sceneId}
            timeout_seconds: ${dwmInferenceTimeoutSeconds}
            duration_seconds: ${dwmInferenceDurationSeconds}
            timeout_usage_ratio: ${dwmInferenceTimeoutUsageRatio}
            timed_out: ${dwmInferenceTimedOut}
            status: "SUCCEEDED"
            start_time: ${dwmInferenceStartTime}
            end_time: ${dwmInferenceEndTime}
          severity: "INFO"
        next: log_dwm_inference_complete_message

    - log_dwm_inference_complete_message:
        call: sys.log
        args:
          text: '${"DWM inference completed for scene " + sceneId}'
          severity: "INFO"
        next: write_inference_completion_marker

    - write_inference_completion_marker:
        call: googleapis.storage.v1.objects.insert
        args:
          bucket: ${bucket}
          name: ${dwmInferenceCompleteMarker}
          uploadType: "media"
          body: '${"{\"scene_id\": \"" + sceneId + "\", \"status\": \"completed\", \"timestamp\": \"" + time.format(sys.now()) + "\"}"}'
        next: done

    - dwm_inference_failed:
        assign:
          - dwmInferenceEndTime: '${time.format(sys.now())}'
          - dwmInferenceDurationSeconds: '${time.parse(dwmInferenceEndTime) - time.parse(dwmInferenceStartTime)}'
          - dwmInferenceTimeoutUsageRatio: '${dwmInferenceDurationSeconds / dwmInferenceTimeoutSeconds}'
          - dwmInferenceTimedOut: '${dwmInferenceDurationSeconds >= dwmInferenceTimeoutSeconds}'
        next: emit_dwm_inference_metrics_failed_from_status

    - emit_dwm_inference_metrics_failed_from_status:
        call: sys.log
        args:
          data:
            bp_metric: "job_invocation"
            event: "complete"
            workflow: "dwm-preparation-pipeline"
            job: ${dwmInferenceJobName}
            scene_id: ${sceneId}
            timeout_seconds: ${dwmInferenceTimeoutSeconds}
            duration_seconds: ${dwmInferenceDurationSeconds}
            timeout_usage_ratio: ${dwmInferenceTimeoutUsageRatio}
            timed_out: ${dwmInferenceTimedOut}
            status: "FAILED"
            start_time: ${dwmInferenceStartTime}
            end_time: ${dwmInferenceEndTime}
          severity: "ERROR"
        next: log_dwm_inference_failed_message

    - log_dwm_inference_failed_message:
        call: sys.log
        args:
          text: '${"WARNING: DWM inference failed for scene " + sceneId}'
          severity: "WARNING"
        next: read_inference_failure_marker

    - read_inference_failure_marker:
        try:
          call: googleapis.storage.v1.objects.get
          args:
            bucket: ${bucket}
            object: ${dwmInferenceFailedMarker}
            alt: "media"
          result: dwmInferenceFailurePayload
        except:
          as: e
          steps:
            - handle_missing_dwm_inference_marker:
                switch:
                  - condition: '${e.code == 404}'
                    next: write_inference_failure_marker
                next: log_dwm_inference_marker_read_error
        next: log_dwm_inference_marker_payload

    - log_dwm_inference_marker_read_error:
        call: sys.log
        args:
          text: '${"Failed to read .failed inference marker for DWM in scene " + sceneId + ": " + e.message}'
          severity: "WARNING"
        next: write_inference_failure_marker

    - log_dwm_inference_marker_payload:
        call: sys.log
        args:
          text: '${"DWM inference failure marker payload for scene " + sceneId + ": " + dwmInferenceFailurePayload}'
          severity: "ERROR"
        next: write_inference_legacy_failure_marker

    - write_inference_failure_marker:
        call: googleapis.storage.v1.objects.insert
        args:
          bucket: ${bucket}
          name: ${dwmInferenceFailedMarker}
          uploadType: "media"
          body: ${json.encode({
            "scene_id": sceneId,
            "job_name": dwmInferenceJobName,
            "status": "failed",
            "timestamp": time.format(sys.now()),
            "error": {
              "code": "dwm_inference_failed",
              "message": "DWM inference failed",
              "type": "workflow_failure",
              "stack_trace": null
            },
            "context": {
              "execution_id": dwmInferenceExecutionName,
              "workflow_execution_id": sys.get_env("GOOGLE_CLOUD_WORKFLOW_EXECUTION_ID"),
              "attempt_number": 1,
              "config_context": {
                "dwm_prefix": dwmPrefix
              }
            },
            "input_params": {
              "scene_id": sceneId,
              "bucket": bucket
            }
          })}
        next: write_inference_legacy_failure_marker

    - write_inference_legacy_failure_marker:
        call: googleapis.storage.v1.objects.insert
        args:
          bucket: ${bucket}
          name: ${dwmInferenceLegacyFailedMarker}
          uploadType: "media"
          body: '${"{\"scene_id\": \"" + sceneId + "\", \"status\": \"failed\", \"timestamp\": \"" + time.format(sys.now()) + "\"}"}'
        next: done_with_failure

    - dwm_failed:
        # DWM failure is non-fatal - scene is still usable for other purposes
        assign:
          - dwmEndTime: '${time.format(sys.now())}'
          - dwmDurationSeconds: '${time.parse(dwmEndTime) - time.parse(dwmStartTime)}'
          - dwmTimeoutUsageRatio: '${dwmDurationSeconds / dwmTimeoutSeconds}'
          - dwmTimedOut: '${dwmDurationSeconds >= dwmTimeoutSeconds}'
        next: emit_dwm_metrics_failed_from_status

    - emit_dwm_metrics_failed_from_status:
        call: sys.log
        args:
          data:
            bp_metric: "job_invocation"
            event: "complete"
            workflow: "dwm-preparation-pipeline"
            job: ${dwmJobName}
            scene_id: ${sceneId}
            timeout_seconds: ${dwmTimeoutSeconds}
            duration_seconds: ${dwmDurationSeconds}
            timeout_usage_ratio: ${dwmTimeoutUsageRatio}
            timed_out: ${dwmTimedOut}
            status: "FAILED"
            start_time: ${dwmStartTime}
            end_time: ${dwmEndTime}
          severity: "ERROR"
        next: log_dwm_failed_message

    - log_dwm_failed_message:
        call: sys.log
        args:
          text: '${"WARNING: DWM preparation failed for scene " + sceneId + " - scene still usable for simulation"}'
          severity: "WARNING"
        next: read_failure_marker

    - read_failure_marker:
        try:
          call: googleapis.storage.v1.objects.get
          args:
            bucket: ${bucket}
            object: ${dwmFailedMarker}
            alt: "media"
          result: dwmFailurePayload
        except:
          as: e
          steps:
            - handle_missing_dwm_failure_marker:
                switch:
                  - condition: '${e.code == 404}'
                    next: write_failure_marker
                next: log_dwm_failure_marker_read_error
        next: log_dwm_failure_marker_payload

    - log_dwm_failure_marker_read_error:
        call: sys.log
        args:
          text: '${"Failed to read .failed marker for DWM in scene " + sceneId + ": " + e.message}'
          severity: "WARNING"
        next: write_failure_marker

    - log_dwm_failure_marker_payload:
        call: sys.log
        args:
          text: '${"DWM failure marker payload for scene " + sceneId + ": " + dwmFailurePayload}'
          severity: "ERROR"
        next: write_legacy_failure_marker

    - write_failure_marker:
        call: googleapis.storage.v1.objects.insert
        args:
          bucket: ${bucket}
          name: ${dwmFailedMarker}
          uploadType: "media"
          body: ${json.encode({
            "scene_id": sceneId,
            "job_name": dwmJobName,
            "status": "failed",
            "timestamp": time.format(sys.now()),
            "error": {
              "code": "dwm_failed",
              "message": "DWM preparation failed",
              "type": "workflow_failure",
              "stack_trace": null
            },
            "context": {
              "execution_id": dwmExecutionName,
              "workflow_execution_id": sys.get_env("GOOGLE_CLOUD_WORKFLOW_EXECUTION_ID"),
              "attempt_number": 1,
              "config_context": {
                "dwm_prefix": dwmPrefix
              }
            },
            "input_params": {
              "scene_id": sceneId,
              "bucket": bucket
            }
          })}
        result: failMarkerResult
        next: write_legacy_failure_marker

    - write_legacy_failure_marker:
        call: googleapis.storage.v1.objects.insert
        args:
          bucket: ${bucket}
          name: ${dwmLegacyFailedMarker}
          uploadType: "media"
          body: '${"{\"scene_id\": \"" + sceneId + "\", \"status\": \"failed\", \"timestamp\": \"" + time.format(sys.now()) + "\"}"}'
        result: legacyFailMarkerResult
        next: done_with_failure

    # =========================================================================
    # Completion
    # =========================================================================

    - done:
        return:
          status: "SUCCESS"
          scene_id: ${sceneId}
          message: '${"DWM preparation and inference completed for scene " + sceneId}'
          dwm_execution: ${dwmExec.name}
          outputs:
            dwm_bundles: '${"scenes/" + sceneId + "/dwm/"}'
            completion_marker: ${dwmCompleteMarker}
            inference_marker: ${dwmInferenceCompleteMarker}

    - done_with_failure:
        return:
          status: "FAILED"
          scene_id: ${sceneId}
          message: '${"DWM preparation failed for scene " + sceneId}'
          dwm_execution: ${dwmExec.name}

    - skip:
        return:
          status: "SKIPPED"
          message: '${"Not a completion marker file: " + object}'
