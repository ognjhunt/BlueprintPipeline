main:
  params: [event]
  steps:
    - log_event:
        call: sys.log
        args:
          text: ${event}
          severity: "INFO"
        next: extract

    - extract:
        assign:
          - bucket: ${event.data.bucket}
          - object: ${event.data.name}
          - projectId: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
          - region: "us-central1"
        next: filter_layout_json

    # Only handle scenes/.../layout/scene_layout.json
    - filter_layout_json:
        switch:
          - condition: ${text.match_regex(object, "^scenes/.+/layout/scene_layout\\.json$")}
            next: derive
        next: skip

    - derive:
        assign:
          - parts: ${text.split(object, "/")}
          - sceneId: ${parts[1]}
          - layoutPrefix: ${"scenes/" + sceneId + "/layout"}
          - jobName: "scale-job"
          - doneMarkerPath: ${"scenes/" + sceneId + "/layout/scene_layout_scaled.done"}
          - lockPath: ${"scenes/" + sceneId + "/layout/.scale_processing_lock"}
        next: check_if_done

    # Check if the output already exists to avoid duplicate processing
    - check_if_done:
        try:
          steps:
            - get_done_marker:
                call: googleapis.storage.v1.objects.get
                args:
                  bucket: ${bucket}
                  object: ${doneMarkerPath}
                result: doneMarkerObject
            - skip_already_done:
                return: ${"scale-job already completed for " + object + " (found done marker)"}
        except:
          as: e
          steps:
            - check_not_found:
                switch:
                  - condition: ${e.code == 404}
                    next: try_acquire_lock
                raise: ${e}
        next: try_acquire_lock

    # Acquire distributed lock using atomic GCS object creation
    - try_acquire_lock:
        try:
          call: http.post
          args:
            url: ${"https://storage.googleapis.com/upload/storage/v1/b/" + bucket + "/o?uploadType=media&name=" + text.url_encode(lockPath) + "&ifGenerationMatch=0"}
            auth:
              type: OAuth2
            headers:
              Content-Type: "application/octet-stream"
            body: ${"locked by workflow at " + string(sys.now())}
          result: lockResult
        except:
          as: lockError
          steps:
            - check_lock_conflict:
                switch:
                  # 412 Precondition Failed means another workflow already has the lock
                  - condition: ${lockError.code == 412}
                    return: ${"scale-job skipped - another workflow is already processing " + object}
                  # 200 with error body can also indicate conflict
                  - condition: ${lockError.code == 200}
                    return: ${"scale-job skipped - lock already exists for " + object}
                raise: ${lockError}
        next: run_scale_job

    - run_scale_job:
        call: googleapis.run.v2.projects.locations.jobs.run
        args:
          name: ${"projects/" + projectId + "/locations/" + region + "/jobs/" + jobName}
          body:
            overrides:
              containerOverrides:
                - env:
                    - name: BUCKET
                      value: ${bucket}
                    - name: SCENE_ID
                      value: ${sceneId}
                    - name: LAYOUT_PREFIX
                      value: ${layoutPrefix}
        result: scaleExec
        next: done

    - done:
        return: ${"scale-job started for " + object}

    - skip:
        return: ${"scale skip " + object}