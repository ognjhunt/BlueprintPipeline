main:
  params: [event]
  steps:
    - log_event:
        call: sys.log
        args:
          text: ${event}
          severity: "INFO"
        next: extract

    - extract:
        assign:
          - bucket: ${event.data.bucket}
          - object: ${event.data.name}
          - projectId: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
          - region: "us-central1"
        next: filter_layout_json

    # Only handle scenes/.../layout/scene_layout.json
    - filter_layout_json:
        switch:
          - condition: ${text.match_regex(object, "^scenes/.+/layout/scene_layout\\.json$")}
            next: derive
        next: skip

    - derive:
        assign:
          - parts: ${text.split(object, "/")}
          - sceneId: ${parts[1]}
          - da3Prefix: ${"scenes/" + sceneId + "/da3"}
          - segDatasetPrefix: ${"scenes/" + sceneId + "/seg/dataset"}
          - layoutPrefix: ${"scenes/" + sceneId + "/layout"}
          - jobName: "objects-job"
        next: check_if_done

    # Check if the output already exists to avoid duplicate processing
    - check_if_done:
        try:
          steps:
            - read_layout:
                call: http.get
                args:
                  url: ${"https://storage.googleapis.com/storage/v1/b/" + bucket + "/o/" + text.url_encode(object) + "?alt=media"}
                  auth:
                    type: OAuth2
                result: layoutResponse
            - parse_layout:
                assign:
                  - layoutData: ${json.decode(text.decode(layoutResponse.body))}
            - check_has_objects:
                switch:
                  - condition: ${len(layoutData.objects) > 0}
                    return: ${"objects-job already completed for " + object + " (objects already present)"}
        except:
          as: e
          steps:
            - log_check_error:
                call: sys.log
                args:
                  text: '${"Failed to check if objects already exist: " + e.message + ". Proceeding with job."}'
                  severity: "WARNING"
        next: run_objects_job

    - run_objects_job:
        try:
          call: googleapis.run.v2.projects.locations.jobs.run
          args:
            name: ${"projects/" + projectId + "/locations/" + region + "/jobs/" + jobName}
            body:
              overrides:
                containerOverrides:
                  - env:
                      - name: BUCKET
                        value: ${bucket}
                      - name: SCENE_ID
                        value: ${sceneId}
                      - name: DA3_PREFIX
                        value: ${da3Prefix}
                      - name: SEG_DATASET_PREFIX
                        value: ${segDatasetPrefix}
                      - name: LAYOUT_PREFIX
                        value: ${layoutPrefix}
          result: objectsExec
        except:
          as: e
          steps:
            - log_job_error:
                call: sys.log
                args:
                  text: ${"ERROR: Failed to start objects-job: " + e.message}
                  severity: "ERROR"
            - write_failure_marker:
                call: googleapis.storage.v1.objects.insert
                args:
                  bucket: ${bucket}
                  name: ${"scenes/" + sceneId + "/objects/.objects_failed"}
                  uploadType: "media"
                  body: ${"{\\"scene_id\\": \\"" + sceneId + "\\", \\"status\\": \\"failed\\", \\"error\\": \\"" + e.message + "\\"}" }
        next: set_objects_execution_name

    - set_objects_execution_name:
        assign:
          - objectsExecutionName: '${if(objectsExec.metadata != null and objectsExec.metadata.name != null, objectsExec.metadata.name, objectsExec.name)}'
        next: wait_for_objects

    - wait_for_objects:
        call: googleapis.run.v2.projects.locations.jobs.executions.get
        args:
          name: ${objectsExecutionName}
        result: objectsStatus
        next: check_objects_status

    - check_objects_status:
        assign:
          - objectsState: '${if(objectsStatus.state != null, objectsStatus.state, if(objectsStatus.status != null, objectsStatus.status.state, null))}'
          - objectsFailedCount: '${if(objectsStatus.failedCount != null, objectsStatus.failedCount, if(objectsStatus.status != null, objectsStatus.status.failedCount, null))}'
          - objectsSucceededCount: '${if(objectsStatus.succeededCount != null, objectsStatus.succeededCount, if(objectsStatus.status != null, objectsStatus.status.succeededCount, null))}'
        next: objects_status_switch

    - objects_status_switch:
        switch:
          - condition: '${objectsState == "FAILED" or (objectsFailedCount != null and objectsFailedCount > 0)}'
            next: objects_failed
          - condition: '${objectsState == "SUCCEEDED" or (objectsSucceededCount != null and objectsSucceededCount > 0)}'
            next: mark_objects_complete
        next: wait_objects_poll

    - wait_objects_poll:
        call: sys.sleep
        args:
          seconds: 10
        next: wait_for_objects

    - objects_failed:
        call: sys.log
        args:
          text: ${"WARNING: Objects job failed for scene " + sceneId + " but continuing pipeline"}
          severity: "WARNING"
        next: mark_objects_complete

    - mark_objects_complete:
        call: googleapis.storage.v1.objects.insert
        args:
          bucket: ${bucket}
          name: ${"scenes/" + sceneId + "/objects/.objects_complete"}
          uploadType: "media"
          body: ${"{\\"scene_id\\": \\"" + sceneId + "\\", \\"status\\": \\"completed\\", \\"timestamp\\": \\"" + time.format(sys.now()) + "\\"}" }
        result: markerResult
        next: done

    - done:
        return: ${"objects-job started for " + object}

    - skip:
        return: ${"objects skip " + object}