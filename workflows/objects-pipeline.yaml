main:
  params: [event]
  steps:
    - log_event:
        call: sys.log
        args:
          text: ${event}
          severity: "INFO"
        next: extract

    - extract:
        assign:
          - bucket: ${event.data.bucket}
          - object: ${event.data.name}
          - projectId: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
          - region: "us-central1"
        next: filter_layout_json

    # Only handle scenes/.../layout/scene_layout.json
    - filter_layout_json:
        switch:
          - condition: ${text.match_regex(object, "^scenes/.+/layout/scene_layout\\.json$")}
            next: derive
        next: skip

    - derive:
        assign:
          - parts: ${text.split(object, "/")}
          - sceneId: ${parts[1]}
          - da3Prefix: ${"scenes/" + sceneId + "/da3"}
          - segDatasetPrefix: ${"scenes/" + sceneId + "/seg/dataset"}
          - layoutPrefix: ${"scenes/" + sceneId + "/layout"}
          - jobName: "objects-job"
          - lockPath: ${"scenes/" + sceneId + "/layout/.objects_processing_lock"}
        next: check_if_done

    # Check if the output already exists to avoid duplicate processing
    - check_if_done:
        try:
          steps:
            - read_layout:
                call: http.get
                args:
                  url: ${"https://storage.googleapis.com/storage/v1/b/" + bucket + "/o/" + text.url_encode(object) + "?alt=media"}
                  auth:
                    type: OAuth2
                result: layoutResponse
            - parse_layout:
                assign:
                  - layoutData: ${json.decode(text.decode(layoutResponse.body))}
            - check_has_objects:
                switch:
                  - condition: ${len(layoutData.objects) > 0}
                    return: ${"objects-job already completed for " + object + " (objects already present)"}
        except:
          as: e
          steps:
            - log_check_error:
                call: sys.log
                args:
                  text: ${"Failed to check if objects already exist: " + e.message + ". Proceeding with job."}
                  severity: "WARNING"
        next: try_acquire_lock

    # Acquire distributed lock using atomic GCS object creation
    - try_acquire_lock:
        try:
          call: http.post
          args:
            url: ${"https://storage.googleapis.com/upload/storage/v1/b/" + bucket + "/o?uploadType=media&name=" + text.url_encode(lockPath) + "&ifGenerationMatch=0"}
            auth:
              type: OAuth2
            headers:
              Content-Type: "application/octet-stream"
            body: ${"locked by workflow at " + string(sys.now())}
          result: lockResult
        except:
          as: lockError
          steps:
            - check_lock_conflict:
                switch:
                  # 412 Precondition Failed means another workflow already has the lock
                  - condition: ${lockError.code == 412}
                    return: ${"objects-job skipped - another workflow is already processing " + object}
                  # 200 with error body can also indicate conflict
                  - condition: ${lockError.code == 200}
                    return: ${"objects-job skipped - lock already exists for " + object}
                raise: ${lockError}
        next: run_objects_job

    - run_objects_job:
        call: googleapis.run.v2.projects.locations.jobs.run
        args:
          name: ${"projects/" + projectId + "/locations/" + region + "/jobs/" + jobName}
          body:
            overrides:
              containerOverrides:
                - env:
                    - name: BUCKET
                      value: ${bucket}
                    - name: SCENE_ID
                      value: ${sceneId}
                    - name: DA3_PREFIX
                      value: ${da3Prefix}
                    - name: SEG_DATASET_PREFIX
                      value: ${segDatasetPrefix}
                    - name: LAYOUT_PREFIX
                      value: ${layoutPrefix}
        result: objectsExec
        next: done

    - done:
        return: ${"objects-job started for " + object}

    - skip:
        return: ${"objects skip " + object}