main:
  params: [event]
  steps:
    - log_event:
        call: sys.log
        args:
          text: ${event}
          severity: "INFO"
        next: extract

    - extract:
        assign:
          - bucket: ${event.data.bucket}
          - object: ${event.data.name}
          - projectId: '${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}'
          - region: "us-central1"
        next: filter_da3_geom

    # Only handle scenes/.../da3/da3_geom.npz
    - filter_da3_geom:
        switch:
          - condition: '${text.match_regex(object, "^scenes/.+/da3/da3_geom\\.npz$")}'
            next: derive
        next: skip

    - derive:
        assign:
          - parts: '${text.split(object, "/")}'
          - sceneId: ${parts[1]}
          - da3Prefix: '${"scenes/" + sceneId + "/da3"}'
          - segDatasetPrefix: '${"scenes/" + sceneId + "/seg/dataset"}'
          - layoutPrefix: '${"scenes/" + sceneId + "/layout"}'
          - jobName: "layout-job"
          - layoutOutputPath: '${"scenes/" + sceneId + "/layout/scene_layout.json"}'
          - lockPath: '${"scenes/" + sceneId + "/layout/.processing_lock"}'
        next: check_if_done

    # Check if the output already exists to avoid duplicate processing
    - check_if_done:
        try:
          steps:
            - get_layout_output:
                call: googleapis.storage.v1.objects.get
                args:
                  bucket: ${bucket}
                  object: ${layoutOutputPath}
                result: layoutOutputObject
            - skip_already_done:
                return: '${"layout-job already completed for " + object + " (found scene_layout.json)"}'
        except:
          as: e
          steps:
            - check_not_found:
                switch:
                  - condition: ${e.code == 404}
                    next: try_acquire_lock
                next: raise_check_error
            - raise_check_error:
                raise: ${e}
        next: try_acquire_lock

    # Try to acquire a processing lock to prevent concurrent runs
    - try_acquire_lock:
        try:
          steps:
            - check_existing_lock:
                call: googleapis.storage.v1.objects.get
                args:
                  bucket: ${bucket}
                  object: ${lockPath}
                result: existingLock
            - skip_locked:
                return: '${"layout-job already processing for " + object + " (lock exists)"}'
        except:
          as: e
          steps:
            - check_lock_not_found:
                switch:
                  - condition: ${e.code == 404}
                    next: create_lock
                next: raise_lock_error
            - raise_lock_error:
                raise: ${e}
        next: skip

    # Create lock file to claim this processing task
    - create_lock:
        try:
          steps:
            - write_lock:
                call: http.post
                args:
                  url: '${"https://storage.googleapis.com/upload/storage/v1/b/" + bucket + "/o?uploadType=media&name=" + text.url_encode(lockPath) + "&ifGenerationMatch=0"}'
                  auth:
                    type: OAuth2
                  headers:
                    Content-Type: "application/json"
                  body: "processing"
                result: lockObject
        except:
          as: e
          steps:
            - log_lock_race:
                call: sys.log
                args:
                  text: '${"Failed to acquire lock (likely race condition): " + e.message}'
                  severity: "WARNING"
                next: return_lock_race
            - return_lock_race:
                return: '${"layout-job lock acquisition failed for " + object}'
        next: run_layout_job

    - run_layout_job:
        call: googleapis.run.v2.projects.locations.jobs.run
        args:
          name: '${"projects/" + projectId + "/locations/" + region + "/jobs/" + jobName}'
          body:
            overrides:
              containerOverrides:
                - env:
                    - name: BUCKET
                      value: ${bucket}
                    - name: SCENE_ID
                      value: ${sceneId}
                    - name: DA3_PREFIX
                      value: ${da3Prefix}
                    - name: SEG_DATASET_PREFIX
                      value: ${segDatasetPrefix}
                    - name: LAYOUT_PREFIX
                      value: ${layoutPrefix}
        result: layoutExec
        next: done

    - done:
        return: '${"layout-job started for " + object}'

    - skip:
        return: '${"layout skip " + object}'