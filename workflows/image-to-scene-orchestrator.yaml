# image-to-scene-orchestrator.yaml
#
# Master orchestrator that runs the ENTIRE image-to-scene pipeline end-to-end
# by directly calling sub-workflows. Replaces the chain of Eventarc triggers.
#
# Stages:
#   1. VM Reconstruction  — start GPU VM, run run_pipeline_gcs.sh (regen3d, simready, usd)
#   2. USD Assembly        — call usd-assembly-pipeline (GLB→USDZ, simready, replicator, isaac-lab)
#   3. Variation Assets    — call variation-assets-pipeline (variation-gen, simready)
#   4. GenieSim Export     — call genie-sim-export-pipeline (export + GKE GPU job)
#   5. Arena Export        — call arena-export-pipeline (non-blocking, best-effort)
#
# Only ONE Eventarc trigger needed: image upload → this workflow → done.
# Sub-workflow YAMLs are called unchanged via workflowexecutions API.
#
# EventArc setup: workflows/setup-orchestrator-trigger.sh

main:
  params: [event]
  steps:
    # =========================================================================
    # INITIALIZATION
    # =========================================================================
    - log_event:
        call: sys.log
        args:
          text: ${event}
          severity: "INFO"
        next: extract

    - extract:
        assign:
          - bucket: ${event.data.bucket}
          - object: ${event.data.name}
          - objectGeneration: '${if(event.data.generation != null, string(event.data.generation), "0")}'
          - objectGenerationInt: '${int(if(event.data.generation != null, string(event.data.generation), "0"))}'
          - projectId: '${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}'
          - region: ${default(sys.get_env("WORKFLOW_REGION"), "us-central1")}
          - vmName: "isaac-sim-ubuntu"
          - vmZone: "us-east1-d"
          - pipelineTimeoutSeconds: 2700
          - pollIntervalSeconds: 30
          - startTime: '${time.format(sys.now())}'
          - elapsedSeconds: 0
          - failedStage: ""
          - completedStages: ""
        next: filter_image_uploads

    - filter_image_uploads:
        switch:
          - condition: '${text.match_regex(object, "^scenes/[^/]+/images/[^/]+\\.([Pp][Nn][Gg]|[Jj][Pp][Ee]?[Gg])$")}'
            next: derive
        next: skip

    - derive:
        assign:
          - parts: '${text.split(object, "/")}'
          - sceneId: ${parts[1]}
          - scenePrefix: '${"scenes/" + sceneId}'
          - completionMarker: '${scenePrefix + "/.reconstruction_complete"}'
          - failureMarker: '${scenePrefix + "/.orchestrator_failed"}'
          - errorCode: ""
          - errorMsg: ""
          - buildId: ""
        next: check_already_processed

    # =========================================================================
    # DEDUPLICATION — skip if already processed for this generation
    # =========================================================================
    - check_already_processed:
        try:
          call: googleapis.storage.v1.objects.get
          args:
            bucket: ${bucket}
            object: ${completionMarker}
            alt: "media"
          result: existingCompletionPayload
        except:
          as: e
          steps:
            - check_not_found:
                switch:
                  - condition: '${e.code == 404}'
                    next: clear_failure_marker_before_run
            - set_marker_check_error:
                assign:
                  - errorCode: "marker_check_failed"
                  - errorMsg: '${"Failed checking completion marker for scene " + sceneId + ": " + e.message}'
                next: build_failure_body
        next: parse_existing_completion_marker

    - parse_existing_completion_marker:
        try:
          assign:
            - completionData: '${json.decode(existingCompletionPayload)}'
            - completedGeneration: '${if(completionData.input_generation != null, string(completionData.input_generation), if(completionData.metadata != null and completionData.metadata.input_generation != null, string(completionData.metadata.input_generation), "0"))}'
            - completedGenerationInt: '${int(completedGeneration)}'
        except:
          as: parseErr
          steps:
            - fallback_existing_marker_generation:
                assign:
                  - completedGeneration: "0"
                  - completedGenerationInt: 0
        next: completion_generation_switch

    - completion_generation_switch:
        switch:
          - condition: '${objectGenerationInt <= completedGenerationInt}'
            next: skip_already_processed
        next: log_rerun_and_clear_markers

    - skip_already_processed:
        call: sys.log
        args:
          text: '${"Skipping stale/duplicate image generation " + objectGeneration + " for scene " + sceneId + " (latest completed generation: " + string(completedGenerationInt) + ")"}'
          severity: "INFO"
        next: skip

    - log_rerun_and_clear_markers:
        call: sys.log
        args:
          text: '${"Newer image generation detected for scene " + sceneId + ": incoming=" + objectGeneration + ", previous=" + string(completedGenerationInt) + ". Clearing stale markers and re-running."}'
          severity: "INFO"
        next: delete_completion_marker

    - delete_completion_marker:
        try:
          call: googleapis.storage.v1.objects.delete
          args:
            bucket: ${bucket}
            object: ${completionMarker}
        except:
          as: deleteCompletionErr
          steps:
            - ignore_missing_completion_marker:
                switch:
                  - condition: '${deleteCompletionErr.code == 404}'
                    next: clear_failure_marker_before_run
            - set_delete_completion_error:
                assign:
                  - errorCode: "marker_cleanup_failed"
                  - errorMsg: '${"Failed clearing previous completion marker for scene " + sceneId + ": " + deleteCompletionErr.message}'
                next: build_failure_body
        next: clear_failure_marker_before_run

    - clear_failure_marker_before_run:
        try:
          call: googleapis.storage.v1.objects.delete
          args:
            bucket: ${bucket}
            object: ${failureMarker}
        except:
          as: deleteFailureErr
          steps:
            - ignore_missing_failure_marker:
                switch:
                  - condition: '${deleteFailureErr.code == 404}'
                    next: log_start
            - set_delete_failure_error:
                assign:
                  - errorCode: "marker_cleanup_failed"
                  - errorMsg: '${"Failed clearing previous failure marker for scene " + sceneId + ": " + deleteFailureErr.message}'
                next: build_failure_body
        next: log_start

    # =========================================================================
    # STAGE 1: VM RECONSTRUCTION
    # =========================================================================
    - log_start:
        call: sys.log
        args:
          text: '${"[orchestrator] Stage 1/5: VM Reconstruction for scene " + sceneId + " (object: " + object + ", generation: " + objectGeneration + ")"}'
          severity: "INFO"
        next: emit_metrics_start

    - emit_metrics_start:
        call: sys.log
        args:
          data:
            bp_metric: "job_invocation"
            event: "start"
            workflow: "image-to-scene-orchestrator"
            job: "full_pipeline"
            scene_id: ${sceneId}
            status: "STARTED"
            start_time: ${startTime}
            input_object: ${object}
            input_generation: ${objectGeneration}
          severity: "INFO"
        next: check_vm_status

    - check_vm_status:
        try:
          call: googleapis.compute.v1.instances.get
          args:
            project: ${projectId}
            zone: ${vmZone}
            instance: ${vmName}
          result: vmInfo
        except:
          as: e
          steps:
            - handle_vm_error:
                assign:
                  - failedStage: "reconstruction"
                  - errorCode: "vm_status_failed"
                  - errorMsg: '${"Failed to get VM status: " + e.message}'
                next: build_failure_body
        next: evaluate_vm_status

    - evaluate_vm_status:
        switch:
          - condition: '${vmInfo.status == "RUNNING"}'
            next: run_pipeline_via_cloud_build
          - condition: '${vmInfo.status == "TERMINATED" or vmInfo.status == "STOPPED"}'
            next: start_vm
        next: vm_unexpected_state

    - vm_unexpected_state:
        assign:
          - failedStage: "reconstruction"
          - errorCode: "vm_unexpected_state"
          - errorMsg: '${"VM " + vmName + " in unexpected state: " + vmInfo.status}'
        next: build_failure_body

    - start_vm:
        call: sys.log
        args:
          text: '${"Starting VM " + vmName + " in " + vmZone + "..."}'
          severity: "INFO"
        next: start_vm_api

    - start_vm_api:
        try:
          call: googleapis.compute.v1.instances.start
          args:
            project: ${projectId}
            zone: ${vmZone}
            instance: ${vmName}
          result: startOp
        except:
          as: e
          steps:
            - handle_start_error:
                assign:
                  - failedStage: "reconstruction"
                  - errorCode: "vm_start_failed"
                  - errorMsg: '${"Failed to start VM: " + e.message}'
                next: build_failure_body
        next: wait_vm_boot

    - wait_vm_boot:
        call: sys.sleep
        args:
          seconds: 60
        next: run_pipeline_via_cloud_build

    - run_pipeline_via_cloud_build:
        try:
          call: googleapis.cloudbuild.v1.projects.builds.create
          args:
            projectId: ${projectId}
            body:
              steps:
                - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
                  entrypoint: "bash"
                  env:
                    - '${"PROJECT_ID=" + projectId}'
                    - '${"VM_NAME=" + vmName}'
                    - '${"VM_ZONE=" + vmZone}'
                    - '${"SCENE_ID=" + sceneId}'
                    - '${"BUCKET=" + bucket}'
                    - '${"OBJECT_NAME=" + object}'
                    - '${"OBJECT_GENERATION=" + objectGeneration}'
                  args:
                    - "-c"
                    - |
                      set -euo pipefail

                      SCENE_ID_Q=$(printf '%q' "${SCENE_ID}")
                      BUCKET_Q=$(printf '%q' "${BUCKET}")
                      OBJECT_NAME_Q=$(printf '%q' "${OBJECT_NAME}")
                      OBJECT_GENERATION_Q=$(printf '%q' "${OBJECT_GENERATION}")

                      REMOTE_CMD="cd ~/BlueprintPipeline && bash run_pipeline_gcs.sh ${SCENE_ID_Q} ${BUCKET_Q} ${OBJECT_NAME_Q} ${OBJECT_GENERATION_Q}"

                      gcloud compute ssh "${VM_NAME}" \
                        --project="${PROJECT_ID}" \
                        --zone="${VM_ZONE}" \
                        --command="${REMOTE_CMD}"
              timeout: '${string(pipelineTimeoutSeconds + 900) + "s"}'
              options:
                logging: CLOUD_LOGGING_ONLY
          result: buildResult
        except:
          as: e
          steps:
            - handle_build_create_error:
                assign:
                  - failedStage: "reconstruction"
                  - errorCode: "pipeline_launch_failed"
                  - errorMsg: '${"Failed to launch pipeline via Cloud Build: " + e.message}'
                next: build_failure_body
        next: init_build_poll

    - init_build_poll:
        assign:
          - buildId: '${if(buildResult.metadata != null and buildResult.metadata.build != null and buildResult.metadata.build.id != null, buildResult.metadata.build.id, if(buildResult.id != null, buildResult.id, ""))}'
          - buildPollStartTime: '${time.format(sys.now())}'
          - buildPollTimeoutSeconds: ${pipelineTimeoutSeconds + 900}
        next: check_build_id

    - check_build_id:
        switch:
          - condition: '${buildId == ""}'
            next: missing_build_id
        next: check_build_status

    - missing_build_id:
        assign:
          - failedStage: "reconstruction"
          - errorCode: "pipeline_launch_failed"
          - errorMsg: '${"Cloud Build returned no build ID for scene " + sceneId}'
        next: build_failure_body

    - check_build_status:
        call: googleapis.cloudbuild.v1.projects.builds.get
        args:
          projectId: ${projectId}
          id: ${buildId}
        result: buildStatus
        next: build_status_switch

    - build_status_switch:
        switch:
          - condition: '${buildStatus.status == "SUCCESS"}'
            next: poll_for_reconstruction
          - condition: '${buildStatus.status == "FAILURE" or buildStatus.status == "TIMEOUT" or buildStatus.status == "CANCELLED" or buildStatus.status == "INTERNAL_ERROR" or buildStatus.status == "EXPIRED"}'
            next: build_failed
        next: check_build_poll_timeout

    - check_build_poll_timeout:
        assign:
          - buildPollNow: '${time.format(sys.now())}'
          - buildPollElapsedSeconds: '${time.parse(buildPollNow) - time.parse(buildPollStartTime)}'
        next: build_poll_timeout_switch

    - build_poll_timeout_switch:
        switch:
          - condition: '${buildPollElapsedSeconds >= buildPollTimeoutSeconds}'
            next: build_poll_timed_out
        next: wait_build_poll

    - wait_build_poll:
        call: sys.sleep
        args:
          seconds: 20
        next: check_build_status

    - build_failed:
        assign:
          - failedStage: "reconstruction"
          - errorCode: "pipeline_build_failed"
          - errorMsg: '${"Pipeline Cloud Build failed for scene " + sceneId + " (build " + buildId + ", status=" + buildStatus.status + ")"}'
        next: build_failure_body

    - build_poll_timed_out:
        assign:
          - failedStage: "reconstruction"
          - errorCode: "pipeline_build_timeout"
          - errorMsg: '${"Pipeline Cloud Build polling timed out for scene " + sceneId + " (build " + buildId + ")"}'
        next: build_failure_body

    - poll_for_reconstruction:
        try:
          call: googleapis.storage.v1.objects.get
          args:
            bucket: ${bucket}
            object: ${completionMarker}
            alt: "media"
          result: completionPayloadRaw
        except:
          as: e
          steps:
            - completion_not_found_switch:
                switch:
                  - condition: '${e.code == 404}'
                    next: check_for_reconstruction_failure
            - log_completion_poll_error:
                call: sys.log
                args:
                  text: '${"GCS marker poll error for scene " + sceneId + ": " + e.message}'
                  severity: "WARNING"
                next: check_reconstruction_timeout
        next: parse_reconstruction_payload

    - parse_reconstruction_payload:
        try:
          assign:
            - completionPayload: '${json.decode(completionPayloadRaw)}'
            - completionGeneration: '${if(completionPayload.input_generation != null, string(completionPayload.input_generation), if(completionPayload.metadata != null and completionPayload.metadata.input_generation != null, string(completionPayload.metadata.input_generation), "0"))}'
            - completionGenerationInt: '${int(completionGeneration)}'
        except:
          as: completionParseErr
          steps:
            - stale_completion_payload:
                assign:
                  - completionGenerationInt: 0
        next: reconstruction_generation_switch

    - reconstruction_generation_switch:
        switch:
          - condition: '${completionGenerationInt >= objectGenerationInt}'
            next: reconstruction_succeeded
        next: check_reconstruction_timeout

    - check_for_reconstruction_failure:
        try:
          call: googleapis.storage.v1.objects.get
          args:
            bucket: ${bucket}
            object: '${scenePrefix + "/.reconstruction_failed"}'
            alt: "media"
          result: failurePayloadRaw
        except:
          as: e
          steps:
            - failure_not_found_switch:
                switch:
                  - condition: '${e.code == 404}'
                    next: check_reconstruction_timeout
            - log_failure_poll_error:
                call: sys.log
                args:
                  text: '${"GCS failure marker poll error for scene " + sceneId + ": " + e.message}'
                  severity: "WARNING"
                next: check_reconstruction_timeout
        next: reconstruction_failed_with_marker

    - reconstruction_failed_with_marker:
        assign:
          - failedStage: "reconstruction"
          - errorCode: "pipeline_failed"
          - errorMsg: '${"Reconstruction failed for scene " + sceneId + " (failure marker found)"}'
        next: build_failure_body

    - check_reconstruction_timeout:
        assign:
          - elapsedSeconds: '${time.parse(time.format(sys.now())) - time.parse(startTime)}'
        next: reconstruction_timeout_switch

    - reconstruction_timeout_switch:
        switch:
          - condition: '${elapsedSeconds >= pipelineTimeoutSeconds}'
            next: reconstruction_timed_out
        next: reconstruction_poll_sleep

    - reconstruction_poll_sleep:
        call: sys.sleep
        args:
          seconds: ${pollIntervalSeconds}
        next: poll_for_reconstruction

    - reconstruction_timed_out:
        assign:
          - failedStage: "reconstruction"
          - errorCode: "pipeline_timeout"
          - errorMsg: '${"Reconstruction timed out after " + string(pipelineTimeoutSeconds) + "s for scene " + sceneId}'
        next: build_failure_body

    - reconstruction_succeeded:
        call: sys.log
        args:
          text: '${"[orchestrator] Stage 1/5 DONE: Reconstruction complete for scene " + sceneId}'
          severity: "INFO"
        next: init_stage_2

    # =========================================================================
    # STAGE 2: USD ASSEMBLY (sub-workflow)
    # =========================================================================
    - init_stage_2:
        assign:
          - completedStages: "reconstruction"
        next: log_stage_2

    - log_stage_2:
        call: sys.log
        args:
          text: '${"[orchestrator] Stage 2/5: USD Assembly for scene " + sceneId}'
          severity: "INFO"
        next: call_usd_assembly

    - build_usd_assembly_arg:
        assign:
          - usdAssemblyEventData:
              bucket: ${bucket}
              name: '${scenePrefix + "/assets/.regen3d_complete"}'
          - usdAssemblyEvent:
              data: ${usdAssemblyEventData}
    - call_usd_assembly:
        try:
          call: googleapis.workflowexecutions.v1.projects.locations.workflows.executions.create
          args:
            parent: '${"projects/" + projectId + "/locations/" + region + "/workflows/usd-assembly-pipeline"}'
            body:
              argument: '${json.encode(usdAssemblyEvent)}'
          result: usdAssemblyExecution
        except:
          as: e
          steps:
            - handle_usd_assembly_call_error:
                assign:
                  - failedStage: "usd_assembly"
                  - errorCode: "subworkflow_call_failed"
                  - errorMsg: '${"Failed to call usd-assembly-pipeline: " + e.message}'
                next: build_failure_body
        next: wait_for_usd_assembly

    - wait_for_usd_assembly:
        call: googleapis.workflowexecutions.v1.projects.locations.workflows.executions.get
        args:
          name: ${usdAssemblyExecution.name}
        result: usdAssemblyStatus
        next: check_usd_assembly_status

    - check_usd_assembly_status:
        switch:
          - condition: '${usdAssemblyStatus.state == "SUCCEEDED"}'
            next: usd_assembly_succeeded
          - condition: '${usdAssemblyStatus.state == "FAILED" or usdAssemblyStatus.state == "CANCELLED"}'
            next: usd_assembly_failed
        next: sleep_usd_assembly

    - sleep_usd_assembly:
        call: sys.sleep
        args:
          seconds: 30
        next: wait_for_usd_assembly

    - usd_assembly_failed:
        assign:
          - failedStage: "usd_assembly"
          - errorCode: "subworkflow_failed"
          - errorMsg: '${"usd-assembly-pipeline failed for scene " + sceneId + " (state: " + usdAssemblyStatus.state + ")"}'
        next: build_failure_body

    - usd_assembly_succeeded:
        call: sys.log
        args:
          text: '${"[orchestrator] Stage 2/5 DONE: USD Assembly complete for scene " + sceneId}'
          severity: "INFO"
        next: init_stage_3

    # =========================================================================
    # STAGE 3: VARIATION ASSETS (sub-workflow)
    # =========================================================================
    - init_stage_3:
        assign:
          - completedStages: "reconstruction,usd_assembly"
        next: log_stage_3

    - log_stage_3:
        call: sys.log
        args:
          text: '${"[orchestrator] Stage 3/5: Variation Assets for scene " + sceneId}'
          severity: "INFO"
        next: call_variation_assets

    - build_variation_assets_arg:
        assign:
          - variationEventData:
              bucket: ${bucket}
              name: '${scenePrefix + "/replicator/.replicator_complete"}'
          - variationEvent:
              data: ${variationEventData}
    - call_variation_assets:
        try:
          call: googleapis.workflowexecutions.v1.projects.locations.workflows.executions.create
          args:
            parent: '${"projects/" + projectId + "/locations/" + region + "/workflows/variation-assets-pipeline"}'
            body:
              argument: '${json.encode(variationEvent)}'
          result: variationAssetsExecution
        except:
          as: e
          steps:
            - handle_variation_call_error:
                assign:
                  - failedStage: "variation_assets"
                  - errorCode: "subworkflow_call_failed"
                  - errorMsg: '${"Failed to call variation-assets-pipeline: " + e.message}'
                next: build_failure_body
        next: wait_for_variation_assets

    - wait_for_variation_assets:
        call: googleapis.workflowexecutions.v1.projects.locations.workflows.executions.get
        args:
          name: ${variationAssetsExecution.name}
        result: variationAssetsStatus
        next: check_variation_assets_status

    - check_variation_assets_status:
        switch:
          - condition: '${variationAssetsStatus.state == "SUCCEEDED"}'
            next: variation_assets_succeeded
          - condition: '${variationAssetsStatus.state == "FAILED" or variationAssetsStatus.state == "CANCELLED"}'
            next: variation_assets_failed
        next: sleep_variation_assets

    - sleep_variation_assets:
        call: sys.sleep
        args:
          seconds: 30
        next: wait_for_variation_assets

    - variation_assets_failed:
        assign:
          - failedStage: "variation_assets"
          - errorCode: "subworkflow_failed"
          - errorMsg: '${"variation-assets-pipeline failed for scene " + sceneId + " (state: " + variationAssetsStatus.state + ")"}'
        next: build_failure_body

    - variation_assets_succeeded:
        call: sys.log
        args:
          text: '${"[orchestrator] Stage 3/5 DONE: Variation Assets complete for scene " + sceneId}'
          severity: "INFO"
        next: init_stage_4

    # =========================================================================
    # STAGE 4: GENIESIM EXPORT (sub-workflow)
    # =========================================================================
    - init_stage_4:
        assign:
          - completedStages: "reconstruction,usd_assembly,variation_assets"
        next: log_stage_4

    - log_stage_4:
        call: sys.log
        args:
          text: '${"[orchestrator] Stage 4/5: GenieSim Export for scene " + sceneId}'
          severity: "INFO"
        next: call_geniesim_export

    - build_geniesim_export_arg:
        assign:
          - geniesimEventData:
              bucket: ${bucket}
              name: '${scenePrefix + "/variation_assets/.variation_pipeline_complete"}'
          - geniesimEvent:
              data: ${geniesimEventData}
    - call_geniesim_export:
        try:
          call: googleapis.workflowexecutions.v1.projects.locations.workflows.executions.create
          args:
            parent: '${"projects/" + projectId + "/locations/" + region + "/workflows/genie-sim-export-pipeline"}'
            body:
              argument: '${json.encode(geniesimEvent)}'
          result: geniesimExportExecution
        except:
          as: e
          steps:
            - handle_geniesim_call_error:
                assign:
                  - failedStage: "geniesim_export"
                  - errorCode: "subworkflow_call_failed"
                  - errorMsg: '${"Failed to call genie-sim-export-pipeline: " + e.message}'
                next: build_failure_body
        next: wait_for_geniesim_export

    - wait_for_geniesim_export:
        call: googleapis.workflowexecutions.v1.projects.locations.workflows.executions.get
        args:
          name: ${geniesimExportExecution.name}
        result: geniesimExportStatus
        next: check_geniesim_export_status

    - check_geniesim_export_status:
        switch:
          - condition: '${geniesimExportStatus.state == "SUCCEEDED"}'
            next: geniesim_export_succeeded
          - condition: '${geniesimExportStatus.state == "FAILED" or geniesimExportStatus.state == "CANCELLED"}'
            next: geniesim_export_failed
        next: sleep_geniesim_export

    - sleep_geniesim_export:
        call: sys.sleep
        args:
          seconds: 30
        next: wait_for_geniesim_export

    - geniesim_export_failed:
        assign:
          - failedStage: "geniesim_export"
          - errorCode: "subworkflow_failed"
          - errorMsg: '${"genie-sim-export-pipeline failed for scene " + sceneId + " (state: " + geniesimExportStatus.state + ")"}'
        next: build_failure_body

    - geniesim_export_succeeded:
        call: sys.log
        args:
          text: '${"[orchestrator] Stage 4/5 DONE: GenieSim Export complete for scene " + sceneId}'
          severity: "INFO"
        next: init_stage_5

    # =========================================================================
    # STAGE 5: ARENA EXPORT (sub-workflow, non-blocking)
    # =========================================================================
    - init_stage_5:
        assign:
          - completedStages: "reconstruction,usd_assembly,variation_assets,geniesim_export"
          - arenaExportState: "SKIPPED"
        next: log_stage_5

    - log_stage_5:
        call: sys.log
        args:
          text: '${"[orchestrator] Stage 5/5: Arena Export for scene " + sceneId + " (non-blocking)"}'
          severity: "INFO"
        next: call_arena_export

    - build_arena_export_arg:
        assign:
          - arenaEventData:
              bucket: ${bucket}
              name: '${scenePrefix + "/geniesim/.geniesim_complete"}'
          - arenaEvent:
              data: ${arenaEventData}
    - call_arena_export:
        try:
          call: googleapis.workflowexecutions.v1.projects.locations.workflows.executions.create
          args:
            parent: '${"projects/" + projectId + "/locations/" + region + "/workflows/arena-export-pipeline"}'
            body:
              argument: '${json.encode(arenaEvent)}'
          result: arenaExportExecution
        except:
          as: arenaCallError
          steps:
            - log_arena_call_failed:
                call: sys.log
                args:
                  text: '${"[orchestrator] Arena export call failed (non-blocking): " + arenaCallError.message}'
                  severity: "WARNING"
                next: orchestrator_done
        next: wait_for_arena_export

    - wait_for_arena_export:
        try:
          call: googleapis.workflowexecutions.v1.projects.locations.workflows.executions.get
          args:
            name: ${arenaExportExecution.name}
          result: arenaExportStatus
        except:
          as: arenaPollError
          steps:
            - log_arena_poll_failed:
                call: sys.log
                args:
                  text: '${"[orchestrator] Arena export poll error (non-blocking): " + arenaPollError.message}'
                  severity: "WARNING"
                next: orchestrator_done
        next: check_arena_export_status

    - check_arena_export_status:
        switch:
          - condition: '${arenaExportStatus.state == "SUCCEEDED"}'
            next: arena_export_done
          - condition: '${arenaExportStatus.state == "FAILED" or arenaExportStatus.state == "CANCELLED"}'
            next: arena_export_failed_nonfatal
        next: sleep_arena_export

    - sleep_arena_export:
        call: sys.sleep
        args:
          seconds: 30
        next: wait_for_arena_export

    - arena_export_failed_nonfatal:
        assign:
          - arenaExportState: "FAILED"
        next: log_arena_nonfatal

    - log_arena_nonfatal:
        call: sys.log
        args:
          text: '${"[orchestrator] Stage 5/5: Arena Export failed (non-blocking) for scene " + sceneId}'
          severity: "WARNING"
        next: orchestrator_done

    - arena_export_done:
        assign:
          - arenaExportState: "SUCCEEDED"
          - completedStages: "reconstruction,usd_assembly,variation_assets,geniesim_export,arena_export"
        next: orchestrator_done

    # =========================================================================
    # SUCCESS
    # =========================================================================
    - orchestrator_done:
        assign:
          - endTime: '${time.format(sys.now())}'
          - durationSeconds: '${time.parse(endTime) - time.parse(startTime)}'
        next: emit_metrics_success

    - emit_metrics_success:
        call: sys.log
        args:
          data:
            bp_metric: "job_invocation"
            event: "complete"
            workflow: "image-to-scene-orchestrator"
            job: "full_pipeline"
            scene_id: ${sceneId}
            duration_seconds: ${durationSeconds}
            status: "SUCCEEDED"
            start_time: ${startTime}
            end_time: ${endTime}
            input_object: ${object}
            input_generation: ${objectGeneration}
            build_id: ${buildId}
            completed_stages: ${completedStages}
            arena_export_state: ${arenaExportState}
          severity: "INFO"
        next: done

    - done:
        return:
          status: "SUCCESS"
          scene_id: ${sceneId}
          message: '${"Full pipeline completed for scene " + sceneId}'
          completed_stages: ${completedStages}
          arena_export: ${arenaExportState}
          outputs:
            completion_marker: ${completionMarker}
            scene_prefix: ${scenePrefix}
            input_object: ${object}
            input_generation: ${objectGeneration}

    # =========================================================================
    # FAILURE HANDLING
    # =========================================================================
    - build_failure_body:
        assign:
          - failureErrorObj:
              code: ${errorCode}
              message: ${errorMsg}
              type: "orchestrator_failure"
              stage: ${failedStage}
          - failureContextObj:
              workflow_execution_id: '${sys.get_env("GOOGLE_CLOUD_WORKFLOW_EXECUTION_ID")}'
              build_id: ${buildId}
              elapsed_seconds: ${elapsedSeconds}
              completed_stages: ${completedStages}
          - failureBody:
              scene_id: ${sceneId}
              status: "failed"
              timestamp: '${time.format(sys.now())}'
              input_object: ${object}
              input_generation: ${objectGeneration}
              error: ${failureErrorObj}
              context: ${failureContextObj}
    - write_failure_and_raise:
        try:
          call: googleapis.storage.v1.objects.insert
          args:
            bucket: ${bucket}
            name: ${failureMarker}
            uploadType: "media"
            body: '${json.encode(failureBody)}'
        except:
          as: writeErr
          steps:
            - log_failure_write_error:
                call: sys.log
                args:
                  text: '${"Failed to write failure marker: " + writeErr.message}'
                  severity: "WARNING"
        next: emit_metrics_failure

    - emit_metrics_failure:
        assign:
          - endTime: '${time.format(sys.now())}'
          - durationSeconds: '${time.parse(endTime) - time.parse(startTime)}'
        next: log_failure_metrics

    - log_failure_metrics:
        call: sys.log
        args:
          data:
            bp_metric: "job_invocation"
            event: "complete"
            workflow: "image-to-scene-orchestrator"
            job: "full_pipeline"
            scene_id: ${sceneId}
            duration_seconds: ${durationSeconds}
            status: "FAILED"
            failed_stage: ${failedStage}
            start_time: ${startTime}
            end_time: ${endTime}
            error: ${errorMsg}
            input_object: ${object}
            input_generation: ${objectGeneration}
            build_id: ${buildId}
            completed_stages: ${completedStages}
          severity: "ERROR"
        next: raise_pipeline_error

    - raise_pipeline_error:
        raise: '${"[" + failedStage + "] " + errorMsg}'

    - skip:
        return:
          status: "SKIPPED"
          message: '${"Not an eligible image upload event: " + object}'
