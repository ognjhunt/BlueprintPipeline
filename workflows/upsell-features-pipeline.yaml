# upsell-features-pipeline.yaml
#
# Google Cloud Workflows pipeline for RETROACTIVE upsell processing.
#
# IMPORTANT: This workflow should NOT be auto-triggered by EventArc!
#
# Upsell features are automatically processed INLINE by episode-generation-job
# when BUNDLE_TIER != standard. This eliminates duplicate processing and
# ensures upsell features are applied immediately after episode generation.
#
# This workflow is for MANUAL/RETROACTIVE use only:
#   - Retroactive upsell processing on existing episodes
#   - Tier upgrades after initial generation
#   - Re-processing after upsell module updates
#   - Testing and debugging
#
# DO NOT configure EventArc auto-trigger for this workflow!
# Instead, run manually when needed:
#   gcloud workflows run upsell-features-pipeline \
#     --location=us-central1 \
#     --data='{"data":{"bucket":"your-bucket","name":"scenes/kitchen_001/episodes/.episodes_complete"},"bundle_tier":"pro","force_reprocess":true}'
#
# The workflow checks for existing upsell_complete markers and skips if found
# unless force_reprocess=true is passed.
#
# If you previously created an EventArc trigger, remove it with:
#   gcloud eventarc triggers delete upsell-features-trigger --location=us-central1

main:
  params: [event]
  steps:
    - log_event:
        call: sys.log
        args:
          text: '${event}'
          severity: "INFO"
        next: extract

    - extract:
        assign:
          - bucket: ${event.data.bucket}
          - object: ${event.data.name}
          - projectId: '${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}'
          - region: "us-central1"
          # Bundle tier can be passed in event or defaults to standard
          - bundleTier: '${default(map.get(event, "bundle_tier"), "standard")}'
          # Force reprocessing even if already completed
          - forceReprocess: '${default(map.get(event, "force_reprocess"), false)}'
        next: filter_completion_markers

    # Filter for .episodes_complete marker files
    - filter_completion_markers:
        switch:
          - condition: '${text.match_regex(object, "^scenes/.+/episodes/\\.episodes_complete$")}'
            next: derive
        next: skip

    - derive:
        assign:
          - parts: '${text.split(object, "/")}'
          - sceneId: ${parts[1]}
          - scenePath: '${"scenes/" + sceneId}'
          - episodesPrefix: '${"scenes/" + sceneId + "/episodes"}'
          - upsellOutputPrefix: '${"scenes/" + sceneId + "/episodes/upsell_outputs"}'
          - upsellCompleteMarker: '${"scenes/" + sceneId + "/episodes/upsell_outputs/.upsell_complete"}'
          - upsellFailedMarker: '${"scenes/" + sceneId + "/episodes/upsell_outputs/.failed"}'
          - upsellLegacyFailedMarker: '${"scenes/" + sceneId + "/episodes/upsell_outputs/.upsell_failed"}'
          - upsellJobName: "upsell-features-job"
        next: check_bundle_tier

    # Skip if standard tier (no upsell features)
    - check_bundle_tier:
        switch:
          - condition: '${bundleTier == "standard"}'
            next: skip_standard_tier
        next: check_already_processed

    - skip_standard_tier:
        call: sys.log
        args:
          text: '${"Standard tier - no upsell features to apply for scene " + sceneId}'
          severity: "INFO"
        next: done_standard

    # Check if upsell features already processed (idempotence)
    # Can be bypassed with force_reprocess=true
    - check_already_processed:
        switch:
          - condition: ${forceReprocess == true}
            next: log_force_reprocess
        next: check_existing_marker

    - log_force_reprocess:
        call: sys.log
        args:
          text: '${"Force reprocessing enabled for scene " + sceneId}'
          severity: "INFO"
        next: log_start

    - check_existing_marker:
        try:
          call: googleapis.storage.v1.objects.get
          args:
            bucket: ${bucket}
            object: ${upsellCompleteMarker}
          result: existingMarker
        except:
          as: e
          steps:
            - check_not_found:
                switch:
                  - condition: '${e.code == 404}'
                    next: log_start
                next: raise_check_error
        next: skip_already_processed

    - skip_already_processed:
        call: sys.log
        args:
          text: '${"Upsell features already processed for scene " + sceneId + " - skipping (use force_reprocess=true to override)"}'
          severity: "INFO"
        next: skip

    - raise_check_error:
        raise: '${e}'

    - log_start:
        call: sys.log
        args:
          text: '${"Upsell features processing triggered for scene " + sceneId + " (tier: " + bundleTier + ")"}'
          severity: "INFO"
        next: run_upsell_job

    # Run upsell features job via Cloud Run
    - run_upsell_job:
        call: googleapis.run.v2.projects.locations.jobs.run
        args:
          name: '${"projects/" + projectId + "/locations/" + region + "/jobs/upsell-features-job"}'
          body:
            overrides:
              containerOverrides:
                - env:
                    - name: BUCKET
                      value: ${bucket}
                    - name: SCENE_ID
                      value: ${sceneId}
                    - name: BUNDLE_TIER
                      value: ${bundleTier}
                    - name: SCENE_PATH
                      value: ${scenePath}
        result: jobResult
        next: set_upsell_execution_name

    - set_upsell_execution_name:
        assign:
          - upsellExecutionName: '${if(jobResult.metadata != null and jobResult.metadata.name != null, jobResult.metadata.name, jobResult.name)}'
        next: wait_for_job

    - wait_for_job:
        call: sys.sleep
        args:
          seconds: 30
        next: check_job_status

    - check_job_status:
        # For Cloud Run Jobs, we check the execution status
        try:
          call: googleapis.run.v2.projects.locations.jobs.executions.get
          args:
            name: ${jobResult.metadata.name}
          result: executionStatus
        except:
          as: e
          steps:
            - log_status_error:
                call: sys.log
                args:
                  text: '${"Error checking job status: " + e.message}'
                  severity: "WARNING"
                next: wait_for_job
        next: job_status_switch

    - job_status_switch:
        switch:
          - condition: '${executionStatus.completionTime != null and executionStatus.succeededCount > 0}'
            next: log_upsell_complete
          - condition: '${executionStatus.completionTime != null and executionStatus.failedCount > 0}'
            next: upsell_job_failed
        next: wait_for_job

    - log_upsell_complete:
        call: sys.log
        args:
          text: '${"Upsell features processing completed for scene " + sceneId}'
          severity: "INFO"
        next: write_completion_marker

    # Write completion marker for downstream processes
    - write_completion_marker:
        call: googleapis.storage.v1.objects.insert
        args:
          bucket: ${bucket}
          name: ${upsellCompleteMarker}
          uploadType: "media"
          body: '${"{\"scene_id\": \"" + sceneId + "\", \"bundle_tier\": \"" + bundleTier + "\", \"status\": \"completed\", \"timestamp\": \"" + time.format(sys.now()) + "\"}"}'
        result: markerResult
        next: done

    - upsell_job_failed:
        # Upsell failure is concerning but not fatal
        call: sys.log
        args:
          text: '${"ERROR: Upsell features processing failed for scene " + sceneId}'
          severity: "ERROR"
        next: read_failure_marker

    - read_failure_marker:
        try:
          call: googleapis.storage.v1.objects.get
          args:
            bucket: ${bucket}
            object: ${upsellFailedMarker}
            alt: "media"
          result: upsellFailurePayload
        except:
          as: e
          steps:
            - handle_missing_upsell_failure_marker:
                switch:
                  - condition: '${e.code == 404}'
                    next: write_failure_marker
                next: log_upsell_failure_marker_read_error
        next: log_upsell_failure_marker_payload

    - log_upsell_failure_marker_read_error:
        call: sys.log
        args:
          text: '${"Failed to read .failed marker for upsell in scene " + sceneId + ": " + e.message}'
          severity: "WARNING"
        next: write_failure_marker

    - log_upsell_failure_marker_payload:
        call: sys.log
        args:
          text: '${"Upsell failure marker payload for scene " + sceneId + ": " + upsellFailurePayload}'
          severity: "ERROR"
        next: write_legacy_failure_marker

    - write_failure_marker:
        call: googleapis.storage.v1.objects.insert
        args:
          bucket: ${bucket}
          name: ${upsellFailedMarker}
          uploadType: "media"
          body: ${json.encode({
            "scene_id": sceneId,
            "job_name": upsellJobName,
            "status": "failed",
            "timestamp": time.format(sys.now()),
            "error": {
              "code": "upsell_features_failed",
              "message": "Upsell features processing failed",
              "type": "workflow_failure",
              "stack_trace": null
            },
            "context": {
              "execution_id": upsellExecutionName,
              "workflow_execution_id": sys.get_env("GOOGLE_CLOUD_WORKFLOW_EXECUTION_ID"),
              "attempt_number": 1,
              "config_context": {
                "upsell_output_prefix": upsellOutputPrefix,
                "bundle_tier": bundleTier
              }
            },
            "input_params": {
              "scene_id": sceneId,
              "bucket": bucket
            }
          })}
        result: failMarkerResult
        next: write_legacy_failure_marker

    - write_legacy_failure_marker:
        call: googleapis.storage.v1.objects.insert
        args:
          bucket: ${bucket}
          name: ${upsellLegacyFailedMarker}
          uploadType: "media"
          body: '${"{\"scene_id\": \"" + sceneId + "\", \"bundle_tier\": \"" + bundleTier + "\", \"status\": \"failed\", \"timestamp\": \"" + time.format(sys.now()) + "\"}"}'
        result: legacyFailMarkerResult
        next: done_with_failure

    # =========================================================================
    # Completion
    # =========================================================================

    - done:
        return:
          status: "SUCCESS"
          scene_id: ${sceneId}
          bundle_tier: ${bundleTier}
          message: '${"Upsell features processing completed for scene " + sceneId}'
          outputs:
            upsell_path: ${upsellOutputPrefix}
            completion_marker: ${upsellCompleteMarker}

    - done_standard:
        return:
          status: "SKIPPED"
          scene_id: ${sceneId}
          bundle_tier: ${bundleTier}
          message: '${"Standard tier - no upsell features for scene " + sceneId}'

    - done_with_failure:
        return:
          status: "FAILED"
          scene_id: ${sceneId}
          bundle_tier: ${bundleTier}
          message: '${"Upsell features processing failed for scene " + sceneId}'

    - skip:
        return:
          status: "SKIPPED"
          message: '${"Not an episodes completion marker file: " + object}'
